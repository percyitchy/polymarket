# Poly Eye - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –°–∏–≥–Ω–∞–ª–æ–≤ –∏ –§—É–Ω–∫—Ü–∏–π

## üîî –ß–∞—Å—Ç—å 1: –¢–∏–ø—ã –°–∏–≥–Ω–∞–ª–æ–≤ - –î–µ—Ç–∞–ª—å–Ω–∞—è –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è

---

## 1. Consensus Alpha Signals (–û—Å–Ω–æ–≤–Ω–æ–π –°–∏–≥–Ω–∞–ª)

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —É—Å–ø–µ—à–Ω—ã–º–∏ —Ç—Ä–µ–π–¥–µ—Ä–∞–º–∏, –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø–æ–∫—É–ø–∞—é—Ç –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∏—Å—Ö–æ–¥ —Ä—ã–Ω–∫–∞ –≤ –∫–æ—Ä–æ—Ç–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–æ—à–µ–ª—å–∫–æ–≤**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç 200+ –∫–æ—à–µ–ª—å–∫–æ–≤ –∫–∞–∂–¥—ã–µ 7 —Å–µ–∫—É–Ω–¥
2. **–í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ 15 –º–∏–Ω—É—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä—ã–Ω–∫–∞/–∏—Å—Ö–æ–¥–∞
3. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ—à–µ–ª—å–∫–æ–≤ (win rate ‚â•70%, –æ–±—ä–µ–º ‚â•$25K, ‚â•12 —Ä—ã–Ω–∫–æ–≤)
4. **–í–∞–ª–∏–¥–∞—Ü–∏—è**: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Ä—ã–Ω–∫–∞ (–∞–∫—Ç–∏–≤–µ–Ω, –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω)
5. **–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω**: –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Ü–µ–Ω –≤—Ö–æ–¥–∞ (‚â§25% –¥–ª—è $0.05-$0.5, ‚â§10% –¥–ª—è ‚â•$0.5)

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket Data API - –¢–æ—Ä–≥–æ–≤—ã–µ –î–∞–Ω–Ω—ã–µ

```python
# Endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ –∫–æ—à–µ–ª—å–∫–∞
GET https://data-api.polymarket.com/trades
Parameters:
  - user: wallet_address (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
  - side: BUY –∏–ª–∏ SELL
  - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
  - market: condition_id (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

# –ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
import requests

def get_wallet_trades(wallet_address: str, side: str = "BUY", limit: int = 10):
    url = "https://data-api.polymarket.com/trades"
    params = {
        "user": wallet_address,
        "side": side,
        "limit": limit
    }
    response = requests.get(url, params=params)
    return response.json()
```

#### 2. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö –ö–æ—à–µ–ª—å–∫–æ–≤ (SQLite)

```python
# –¢–∞–±–ª–∏—Ü–∞ wallets —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ—à–µ–ª—å–∫–∞—Ö
SELECT address, win_rate, traded_total, realized_pnl_total, daily_trading_frequency
FROM wallets
WHERE is_tracked = 1
  AND win_rate >= 0.70
  AND traded_total >= 12
  AND realized_pnl_total >= 25000
```

#### 3. Polymarket CLOB API - –°—Ç–∞—Ç—É—Å –†—ã–Ω–∫–∞

```python
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Ä—ã–Ω–∫–∞
GET https://clob.polymarket.com/markets/{condition_id}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω—ã
GET https://clob.polymarket.com/price
Headers:
  X-API-KEY: your_key
  X-API-SECRET: your_secret
  X-API-PASSPHRASE: your_passphrase
Parameters:
  - token_id: condition_id:outcome_index
  - side: BUY –∏–ª–∏ SELL
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class ConsensusDetector:
    def __init__(self, db, window_minutes=15, min_consensus=3):
        self.db = db
        self.window_minutes = window_minutes
        self.min_consensus = min_consensus
        self.rolling_windows = {}  # condition_id:outcome_index -> {wallets: [], timestamps: []}
    
    def process_trade(self, wallet_address: str, condition_id: str, 
                     outcome_index: int, side: str, price: float, timestamp: datetime):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ–≤—É—é —Å–¥–µ–ª–∫—É –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å"""
        key = f"{condition_id}:{outcome_index}:{side}"
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –æ–∫–Ω–æ
        if key not in self.rolling_windows:
            self.rolling_windows[key] = {
                "wallets": [],
                "timestamps": [],
                "prices": []
            }
        
        window = self.rolling_windows[key]
        
        # –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Å–¥–µ–ª–∫–∏ (—Å—Ç–∞—Ä—à–µ window_minutes)
        cutoff_time = timestamp - timedelta(minutes=self.window_minutes)
        valid_indices = [
            i for i, ts in enumerate(window["timestamps"]) 
            if ts >= cutoff_time
        ]
        
        window["wallets"] = [window["wallets"][i] for i in valid_indices]
        window["timestamps"] = [window["timestamps"][i] for i in valid_indices]
        window["prices"] = [window["prices"][i] for i in valid_indices]
        
        # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Å–¥–µ–ª–∫—É
        if wallet_address not in window["wallets"]:
            window["wallets"].append(wallet_address)
            window["timestamps"].append(timestamp)
            window["prices"].append(price)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å
        unique_wallets = len(set(window["wallets"]))
        if unique_wallets >= self.min_consensus:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Ü–µ–Ω
            if self._validate_price_divergence(window["prices"]):
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Ä—ã–Ω–∫–∞
                if self._is_market_active(condition_id):
                    return self._create_consensus_signal(
                        condition_id, outcome_index, side,
                        window["wallets"], window["prices"], timestamp
                    )
        
        return None
    
    def _validate_price_divergence(self, prices: List[float]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Ü–µ–Ω"""
        if len(prices) < 3:
            return True
        
        avg_price = sum(prices) / len(prices)
        
        # –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
        if avg_price < 0.05:
            # –î–ª—è –Ω–∏–∑–∫–∏—Ö —Ü–µ–Ω —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ
            return True
        elif 0.05 <= avg_price < 0.5:
            # –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ ‚â§ 25%
            max_divergence = 0.25
        else:
            # –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ ‚â§ 10%
            max_divergence = 0.10
        
        for price in prices:
            divergence = abs(price - avg_price) / avg_price
            if divergence > max_divergence:
                return False
        
        return True
    
    def _is_market_active(self, condition_id: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∞–∫—Ç–∏–≤–µ–Ω –ª–∏ —Ä—ã–Ω–æ–∫"""
        # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ä—ã–Ω–∫–∞ —á–µ—Ä–µ–∑ CLOB API
        url = f"https://clob.polymarket.com/markets/{condition_id}"
        response = requests.get(url)
        
        if response.status_code == 200:
            market_data = response.json()
            status = market_data.get("status", "")
            
            # –†—ã–Ω–æ–∫ –∑–∞–∫—Ä—ã—Ç –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å: closed, resolved, finished
            if status in ["closed", "resolved", "finished"]:
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–Ω—É (–µ—Å–ª–∏ —Ü–µ–Ω–∞ >= 0.999 –∏–ª–∏ <= 0.001, —Ä—ã–Ω–æ–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω)
            # –≠—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ü–µ–Ω—ã
        
        return True
```

### –°–∏–ª–∞ –°–∏–≥–Ω–∞–ª–∞

- **–°–ª–∞–±—ã–π**: 3 –∫–æ—à–µ–ª—å–∫–∞, <$5K –æ–±—â–∞—è –ø–æ–∑–∏—Ü–∏—è
- **–£–º–µ—Ä–µ–Ω–Ω—ã–π**: 4-5 –∫–æ—à–µ–ª—å–∫–æ–≤, $5K-$10K –æ–±—â–∞—è –ø–æ–∑–∏—Ü–∏—è
- **–°–∏–ª—å–Ω—ã–π**: 6+ –∫–æ—à–µ–ª—å–∫–æ–≤, >$10K –æ–±—â–∞—è –ø–æ–∑–∏—Ü–∏—è
- **–û—á–µ–Ω—å —Å–∏–ª—å–Ω—ã–π**: –í–∫–ª—é—á–∞–µ—Ç A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤

---

## 2. A-List Trader Consensus (–ü—Ä–µ–º–∏—É–º –°–∏–≥–Ω–∞–ª)

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É A-list —Ç—Ä–µ–π–¥–µ—Ä–∞–º–∏ (—Ç–æ–ø 1% –ø–æ –æ–±—ä–µ–º—É/–ø—Ä–∏–±—ã–ª–∏) –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä—ã–Ω–∫–æ–≤.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è A-list**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –∏–∑ weekly/monthly –ª–∏–¥–µ—Ä–±–æ—Ä–¥–æ–≤
2. **–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (Politics, Sports, Crypto –∏ —Ç.–¥.)
3. **–ö–æ–Ω—Å–µ–Ω—Å—É—Å**: –¢—Ä–µ–±—É–µ—Ç 2+ A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞
4. **–†–æ—É—Ç–∏–Ω–≥**: –ù–∞–ø—Ä–∞–≤–ª—è–µ—Ç –≤ –ø—Ä–µ–º–∏—É–º Telegram —Ç–æ–ø–∏–∫

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket Leaderboards API

```python
# Weekly leaderboard
GET https://polymarket.com/leaderboard/overall/weekly/profit

# Monthly leaderboard  
GET https://polymarket.com/leaderboard/overall/monthly/profit

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Playwright –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ (—Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ SPA)
from playwright.sync_api import sync_playwright

def scrape_leaderboard(url: str, max_pages: int = 20):
    """–°–∫—Ä–∞–ø–∏—Ç—å –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤"""
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        page.goto(url)
        
        wallets = []
        for page_num in range(max_pages):
            # –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            page.wait_for_selector('.leaderboard-row')
            
            # –ò–∑–≤–ª–µ—á—å –∞–¥—Ä–µ—Å–∞ –∫–æ—à–µ–ª—å–∫–æ–≤
            rows = page.query_selector_all('.leaderboard-row')
            for row in rows:
                wallet_link = row.query_selector('a[href*="/profile/"]')
                if wallet_link:
                    href = wallet_link.get_attribute('href')
                    wallet_address = href.split('/')[-1]
                    wallets.append(wallet_address)
            
            # –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            next_button = page.query_selector('button[aria-label="Next"]')
            if next_button and next_button.is_enabled():
                next_button.click()
                page.wait_for_timeout(2000)  # –ü–æ–¥–æ–∂–¥–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
            else:
                break
        
        browser.close()
        return wallets
```

#### 2. Polymarket Analytics API

```python
# –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–π–¥–µ—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
GET https://polymarketanalytics.com/api/traders-tag-performance

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–≥—É—Ç –≤–∫–ª—é—á–∞—Ç—å:
# - wallet_address
# - category (Politics, Sports, Crypto, etc.)
# - time_period (weekly, monthly, all-time)
```

#### 3. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - A-List –ö–æ—à–µ–ª—å–∫–∏

```python
# –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –¥–ª—è A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤
CREATE TABLE a_list_wallets (
    address TEXT PRIMARY KEY,
    category TEXT,
    weekly_rank INTEGER,
    monthly_rank INTEGER,
    total_volume REAL,
    total_profit REAL,
    added_at TEXT,
    updated_at TEXT
);

# –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è A-list:
# - –¢–æ–ø 1% –ø–æ –æ–±—ä–µ–º—É –∏–ª–∏ –ø—Ä–∏–±—ã–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
# - –ò–ª–∏ —Ç–æ–ø 50 –≤ –æ–±—â–µ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class AListConsensusDetector:
    def __init__(self, db, min_a_list_traders=2):
        self.db = db
        self.min_a_list_traders = min_a_list_traders
        self.a_list_wallets = self._load_a_list_wallets()
    
    def _load_a_list_wallets(self) -> Dict[str, Dict]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å A-list –∫–æ—à–µ–ª—å–∫–∏ –∏–∑ –ë–î"""
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT address, category, weekly_rank, monthly_rank
                FROM a_list_wallets
            """)
            rows = cursor.fetchall()
            
            a_list = {}
            for row in rows:
                address, category, weekly_rank, monthly_rank = row
                a_list[address] = {
                    "category": category,
                    "weekly_rank": weekly_rank,
                    "monthly_rank": monthly_rank
                }
            return a_list
    
    def check_a_list_consensus(self, wallets: List[str], 
                              condition_id: str, category: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å A-list —Ç—Ä–µ–π–¥–µ—Ä–æ–≤"""
        a_list_count = 0
        a_list_wallets = []
        
        for wallet in wallets:
            if wallet.lower() in self.a_list_wallets:
                wallet_info = self.a_list_wallets[wallet.lower()]
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
                if not category or wallet_info["category"] == category:
                    a_list_count += 1
                    a_list_wallets.append(wallet)
        
        return a_list_count >= self.min_a_list_traders, a_list_wallets
    
    def update_a_list_wallets(self):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ A-list –∫–æ—à–µ–ª—å–∫–æ–≤ –∏–∑ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–æ–≤"""
        # –°–∫—Ä–∞–ø–∏—Ç—å weekly –∏ monthly –ª–∏–¥–µ—Ä–±–æ—Ä–¥—ã
        weekly_wallets = scrape_leaderboard(
            "https://polymarket.com/leaderboard/overall/weekly/profit"
        )
        monthly_wallets = scrape_leaderboard(
            "https://polymarket.com/leaderboard/overall/monthly/profit"
        )
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ø 50
        all_wallets = list(set(weekly_wallets + monthly_wallets))
        
        # –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ
        for wallet in all_wallets[:50]:  # –¢–æ–ø 50
            # –ü–æ–ª—É—á–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            performance = get_trader_performance(wallet)
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
            self._save_a_list_wallet(wallet, performance)
```

---

## 3. Whale Position Alerts

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∫—Ä—É–ø–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ (>$10K) –æ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∫–æ—à–µ–ª—å–∫–æ–≤, —Ä–∞–∑–ª–∏—á–∞—è –≤—Ö–æ–¥—ã –∏ –≤—ã—Ö–æ–¥—ã.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–π**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
2. **–†–∞—Å—á–µ—Ç USD**: –í—ã—á–∏—Å–ª—è–µ—Ç USD —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–∑–∏—Ü–∏–π
3. **–†–∞–∑–ª–∏—á–µ–Ω–∏–µ**: –†–∞–∑–ª–∏—á–∞–µ—Ç –≤—Ö–æ–¥ (entry) –∏ –≤—ã—Ö–æ–¥ (exit) —Å–∏–≥–Ω–∞–ª—ã
4. **–ü–∞—Ç—Ç–µ—Ä–Ω—ã**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–∏—Ç–æ–≤

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket Data API - –ó–∞–∫—Ä—ã—Ç—ã–µ –ü–æ–∑–∏—Ü–∏–∏

```python
# –ü–æ–ª—É—á–∏—Ç—å –∑–∞–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞
GET https://data-api.polymarket.com/closed-positions
Parameters:
  - user: wallet_address
  - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π
  - market: condition_id (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

def get_closed_positions(wallet_address: str, limit: int = 100):
    url = "https://data-api.polymarket.com/closed-positions"
    params = {
        "user": wallet_address,
        "limit": limit
    }
    response = requests.get(url, params=params)
    return response.json()
```

#### 2. Polymarket Data API - –ê–∫—Ç–∏–≤–Ω—ã–µ –ü–æ–∑–∏—Ü–∏–∏

```python
# –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞
GET https://data-api.polymarket.com/positions
Parameters:
  - user: wallet_address
  - market: condition_id (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

def get_active_positions(wallet_address: str):
    url = "https://data-api.polymarket.com/positions"
    params = {"user": wallet_address}
    response = requests.get(url, params=params)
    return response.json()
```

#### 3. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ò—Å—Ç–æ—Ä–∏—è –ü–æ–∑–∏—Ü–∏–π

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π
CREATE TABLE wallet_positions (
    wallet_address TEXT,
    condition_id TEXT,
    outcome_index INTEGER,
    position_size REAL,
    position_type TEXT,  -- 'long' –∏–ª–∏ 'short'
    usd_value REAL,
    first_seen_at TEXT,
    last_updated_at TEXT,
    PRIMARY KEY (wallet_address, condition_id, outcome_index)
);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class WhalePositionDetector:
    def __init__(self, db, min_whale_size_usd=10000):
        self.db = db
        self.min_whale_size_usd = min_whale_size_usd
        self.previous_positions = {}  # wallet -> {condition_id:outcome -> size}
    
    def monitor_positions(self, wallet_address: str):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞ –∏ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è"""
        # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
        current_positions = self._get_current_positions(wallet_address)
        
        # –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
        previous = self.previous_positions.get(wallet_address, {})
        
        # –û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
        for key, current_size in current_positions.items():
            previous_size = previous.get(key, 0)
            
            if current_size > previous_size:
                # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ (entry)
                change = current_size - previous_size
                usd_value = self._calculate_usd_value(key, change)
                
                if usd_value >= self.min_whale_size_usd:
                    self._create_whale_entry_alert(
                        wallet_address, key, change, usd_value
                    )
            
            elif current_size < previous_size:
                # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ (exit)
                change = previous_size - current_size
                usd_value = self._calculate_usd_value(key, change)
                
                if usd_value >= self.min_whale_size_usd:
                    self._create_whale_exit_alert(
                        wallet_address, key, change, usd_value
                    )
        
        # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
        self.previous_positions[wallet_address] = current_positions
    
    def _get_current_positions(self, wallet_address: str) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞"""
        positions_data = get_active_positions(wallet_address)
        
        positions = {}
        for pos in positions_data:
            condition_id = pos.get("condition_id")
            outcome_index = pos.get("outcome_index")
            size = float(pos.get("size", 0))
            
            if size > 0:
                key = f"{condition_id}:{outcome_index}"
                positions[key] = size
        
        return positions
    
    def _calculate_usd_value(self, position_key: str, size: float) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å USD —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–∑–∏—Ü–∏–∏"""
        condition_id, outcome_index = position_key.split(":")
        
        # –ü–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É —Ç–æ–∫–µ–Ω–∞
        token_id = f"{condition_id}:{outcome_index}"
        price = get_token_price(token_id)
        
        # USD —Å—Ç–æ–∏–º–æ—Å—Ç—å = —Ä–∞–∑–º–µ—Ä * —Ü–µ–Ω–∞
        usd_value = size * price
        return usd_value
    
    def _create_whale_entry_alert(self, wallet: str, position_key: str, 
                                  size: float, usd_value: float):
        """–°–æ–∑–¥–∞—Ç—å –∞–ª–µ—Ä—Ç –æ –≤—Ö–æ–¥–µ –∫–∏—Ç–∞"""
        condition_id, outcome_index = position_key.split(":")
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä—ã–Ω–∫–µ
        market_info = get_market_info(condition_id)
        
        alert = {
            "type": "whale_entry",
            "wallet": wallet,
            "condition_id": condition_id,
            "outcome_index": int(outcome_index),
            "position_size": size,
            "usd_value": usd_value,
            "market_title": market_info.get("title"),
            "market_slug": market_info.get("slug"),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∞–ª–µ—Ä—Ç
        send_whale_alert(alert)
```

---

## 4. Open Interest (OI) Spike Detection

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –≤–Ω–µ–∑–∞–ø–Ω—ã–µ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞ (>50% —Å–ø–∞–π–∫), —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ —Å–∏–ª—å–Ω–æ–µ —É–±–µ–∂–¥–µ–Ω–∏–µ —Ä—ã–Ω–∫–∞.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ OI**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞ –ø–æ –≤—Å–µ–º —Ä—ã–Ω–∫–∞–º
2. **–†–∞—Å—á–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π**: –í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞
3. **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è**: –ö–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
4. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –§–∏–ª—å—Ç—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (–º–∞–ª—ã–µ —Ä—ã–Ω–∫–∏, –Ω–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å)

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket CLOB API - Market Data

```python
# –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ä—ã–Ω–∫–∞ –≤–∫–ª—é—á–∞—è –æ—Ç–∫—Ä—ã—Ç—ã–π –∏–Ω—Ç–µ—Ä–µ—Å
GET https://clob.polymarket.com/markets/{condition_id}

# –û—Ç–≤–µ—Ç –≤–∫–ª—é—á–∞–µ—Ç:
# - openInterest: –æ—Ç–∫—Ä—ã—Ç—ã–π –∏–Ω—Ç–µ—Ä–µ—Å
# - volume24h: –æ–±—ä–µ–º –∑–∞ 24 —á–∞—Å–∞
# - liquidity: –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å

def get_market_oi(condition_id: str):
    url = f"https://clob.polymarket.com/markets/{condition_id}"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        return {
            "open_interest": float(data.get("openInterest", 0)),
            "volume_24h": float(data.get("volume24h", 0)),
            "liquidity": float(data.get("liquidity", 0))
        }
    return None
```

#### 2. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ò—Å—Ç–æ—Ä–∏—è OI

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ OI
CREATE TABLE oi_history (
    condition_id TEXT,
    outcome_index INTEGER,
    open_interest REAL,
    timestamp TEXT,
    PRIMARY KEY (condition_id, outcome_index, timestamp)
);

# –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX idx_oi_timestamp ON oi_history(timestamp);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class OISpikeDetector:
    def __init__(self, db, spike_threshold=0.5, min_liquidity=1000):
        self.db = db
        self.spike_threshold = spike_threshold  # 50% —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
        self.min_liquidity = min_liquidity  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    
    def check_oi_spike(self, condition_id: str, outcome_index: int):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∞–π–∫ –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞"""
        # –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π OI
        current_oi_data = get_market_oi(condition_id)
        if not current_oi_data:
            return None
        
        current_oi = current_oi_data["open_interest"]
        liquidity = current_oi_data["liquidity"]
        
        # –§–∏–ª—å—Ç—Ä: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        if liquidity < self.min_liquidity:
            return None
        
        # –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π OI (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1 —á–∞—Å)
        historical_oi = self._get_historical_oi(
            condition_id, outcome_index, hours=1
        )
        
        if not historical_oi or len(historical_oi) < 2:
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π OI –¥–ª—è –±—É–¥—É—â–∏—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
            self._save_oi_snapshot(condition_id, outcome_index, current_oi)
            return None
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–∏–π OI –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        avg_oi = sum(historical_oi) / len(historical_oi)
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        if avg_oi > 0:
            spike_percent = (current_oi - avg_oi) / avg_oi
        else:
            spike_percent = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä–æ–≥ —Å–ø–∞–π–∫–∞
        if spike_percent >= self.spike_threshold:
            return self._create_oi_spike_alert(
                condition_id, outcome_index,
                old_oi=avg_oi,
                new_oi=current_oi,
                spike_percent=spike_percent
            )
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π OI
        self._save_oi_snapshot(condition_id, outcome_index, current_oi)
        return None
    
    def _get_historical_oi(self, condition_id: str, outcome_index: int, 
                          hours: int) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π OI –∏–∑ –ë–î"""
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours)
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT open_interest
                FROM oi_history
                WHERE condition_id = ? AND outcome_index = ?
                  AND timestamp >= ?
                ORDER BY timestamp DESC
            """, (condition_id, outcome_index, cutoff_time.isoformat()))
            
            rows = cursor.fetchall()
            return [row[0] for row in rows]
    
    def _save_oi_snapshot(self, condition_id: str, outcome_index: int, oi: float):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–Ω–∏–º–æ–∫ OI –≤ –ë–î"""
        timestamp = datetime.now(timezone.utc).isoformat()
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT OR REPLACE INTO oi_history 
                (condition_id, outcome_index, open_interest, timestamp)
                VALUES (?, ?, ?, ?)
            """, (condition_id, outcome_index, oi, timestamp))
            conn.commit()
```

---

## 5. Order Flow Analysis

### –û–ø–∏—Å–∞–Ω–∏–µ

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–∫–∏/–ø—Ä–æ–¥–∞–∂–∏ –∏ –¥–∏–Ω–∞–º–∏–∫—É order book –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏–π —Ü–µ–Ω—ã.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Order Book**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –≥–ª—É–±–∏–Ω—É order book —á–µ—Ä–µ–∑ CLOB API
2. **–†–∞—Å—á–µ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞**: –í—ã—á–∏—Å–ª—è–µ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å bid/ask
3. **–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –æ—Ä–¥–µ—Ä–æ–≤**: –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –æ—Ä–¥–µ—Ä–æ–≤
4. **–ü–∞—Ç—Ç–µ—Ä–Ω—ã**: –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ—Ç–æ–∫–∞ –æ—Ä–¥–µ—Ä–æ–≤

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket CLOB API - Order Book

```python
# –ü–æ–ª—É—á–∏—Ç—å order book –¥–ª—è —Ç–æ–∫–µ–Ω–∞
GET https://clob.polymarket.com/book
Parameters:
  - token_id: condition_id:outcome_index

def get_order_book(token_id: str):
    url = "https://clob.polymarket.com/book"
    params = {"token_id": token_id}
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        data = response.json()
        return {
            "bids": data.get("bids", []),  # –°–ø–∏—Å–æ–∫ –æ—Ä–¥–µ—Ä–æ–≤ –Ω–∞ –ø–æ–∫—É–ø–∫—É
            "asks": data.get("asks", [])   # –°–ø–∏—Å–æ–∫ –æ—Ä–¥–µ—Ä–æ–≤ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É
        }
    return None
```

#### 2. Polymarket CLOB API - Trades Stream

```python
# –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏
GET https://clob.polymarket.com/data/trades
Parameters:
  - token_id: condition_id:outcome_index
  - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫

def get_recent_trades(token_id: str, limit: int = 50):
    url = "https://clob.polymarket.com/data/trades"
    params = {
        "token_id": token_id,
        "limit": limit
    }
    response = requests.get(url, params=params)
    return response.json()
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class OrderFlowAnalyzer:
    def __init__(self, db):
        self.db = db
    
    def analyze_order_flow(self, condition_id: str, outcome_index: int):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ç–æ–∫ –æ—Ä–¥–µ—Ä–æ–≤ –¥–ª—è —Ä—ã–Ω–∫–∞"""
        token_id = f"{condition_id}:{outcome_index}"
        
        # –ü–æ–ª—É—á–∏—Ç—å order book
        order_book = get_order_book(token_id)
        if not order_book:
            return None
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å bid/ask
        bid_volume = sum([bid["size"] for bid in order_book["bids"]])
        ask_volume = sum([ask["size"] for ask in order_book["asks"]])
        
        total_volume = bid_volume + ask_volume
        if total_volume == 0:
            return None
        
        bid_ratio = bid_volume / total_volume
        ask_ratio = ask_volume / total_volume
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞–≤–ª–µ–Ω–∏–µ
        pressure = "buy" if bid_ratio > 0.6 else "sell" if ask_ratio > 0.6 else "neutral"
        
        # –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        recent_trades = get_recent_trades(token_id, limit=20)
        buy_trades = [t for t in recent_trades if t.get("side") == "BUY"]
        sell_trades = [t for t in recent_trades if t.get("side") == "SELL"]
        
        buy_volume = sum([t.get("size", 0) for t in buy_trades])
        sell_volume = sum([t.get("size", 0) for t in sell_trades])
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å–∏–ª—É –¥–∞–≤–ª–µ–Ω–∏—è
        if buy_volume + sell_volume > 0:
            trade_pressure_ratio = buy_volume / (buy_volume + sell_volume)
        else:
            trade_pressure_ratio = 0.5
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        confirmed = False
        if pressure == "buy" and trade_pressure_ratio > 0.6:
            confirmed = True
        elif pressure == "sell" and trade_pressure_ratio < 0.4:
            confirmed = True
        
        return {
            "pressure": pressure,
            "bid_volume": bid_volume,
            "ask_volume": ask_volume,
            "bid_ratio": bid_ratio,
            "ask_ratio": ask_ratio,
            "trade_pressure_ratio": trade_pressure_ratio,
            "confirmed": confirmed
        }
```

---

## 6. Insider Pattern Detection

### –û–ø–∏—Å–∞–Ω–∏–µ

–ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –∏–Ω—Å–∞–π–¥–µ—Ä—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ù–æ–≤—ã–µ –∫–æ—à–µ–ª—å–∫–∏**: –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –∫–æ—à–µ–ª—å–∫–∏ —Å –∫—Ä—É–ø–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏ (>$5K)
2. **–í—ã—Å–æ–∫–∏–π win rate**: –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–∏–π win rate –Ω–∞ –ø–µ—Ä–≤—ã—Ö —Å–¥–µ–ª–∫–∞—Ö (>80%)
3. **–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è**: –ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–æ–±—ã—á–Ω—É—é –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä—ã–Ω–∫–∞—Ö
4. **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—ã—á–Ω–æ–µ –≤—Ä–µ–º—è (–ø–µ—Ä–µ–¥ –∫—Ä—É–ø–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏)

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket Data API - –ò—Å—Ç–æ—Ä–∏—è –°–¥–µ–ª–æ–∫

```python
# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–¥–µ–ª–∫–∏ –∫–æ—à–µ–ª—å–∫–∞
GET https://data-api.polymarket.com/trades
Parameters:
  - user: wallet_address
  - limit: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–¥–æ 500)

def get_all_wallet_trades(wallet_address: str):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–¥–µ–ª–∫–∏ –∫–æ—à–µ–ª—å–∫–∞"""
    all_trades = []
    limit = 500
    offset = 0
    
    while True:
        url = "https://data-api.polymarket.com/trades"
        params = {
            "user": wallet_address,
            "limit": limit,
            "offset": offset
        }
        response = requests.get(url, params=params)
        trades = response.json()
        
        if not trades or len(trades) == 0:
            break
        
        all_trades.extend(trades)
        offset += limit
        
        if len(trades) < limit:
            break
    
    return all_trades
```

#### 2. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ù–æ–≤—ã–µ –ö–æ—à–µ–ª—å–∫–∏

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–æ—à–µ–ª—å–∫–æ–≤
CREATE TABLE new_wallets (
    address TEXT PRIMARY KEY,
    first_seen_at TEXT,
    first_trade_at TEXT,
    first_trade_size REAL,
    total_trades INTEGER DEFAULT 0,
    win_rate REAL,
    is_insider_candidate INTEGER DEFAULT 0
);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class InsiderDetector:
    def __init__(self, db, min_position_size=5000, min_win_rate=0.80):
        self.db = db
        self.min_position_size = min_position_size
        self.min_win_rate = min_win_rate
    
    def detect_insider_patterns(self, wallet_address: str):
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∏–Ω—Å–∞–π–¥–µ—Ä—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–æ—à–µ–ª—å–∫–∞"""
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–æ–≤—ã–π –ª–∏ —ç—Ç–æ –∫–æ—à–µ–ª–µ–∫
        if not self._is_new_wallet(wallet_address):
            return None
        
        # –ü–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–≤—ã–µ —Å–¥–µ–ª–∫–∏
        trades = get_all_wallet_trades(wallet_address)
        if len(trades) < 3:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        trades.sort(key=lambda x: x.get("timestamp", ""))
        first_trades = trades[:10]  # –ü–µ—Ä–≤—ã–µ 10 —Å–¥–µ–ª–æ–∫
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –ö—Ä—É–ø–Ω–∞—è –ø–µ—Ä–≤–∞—è –ø–æ–∑–∏—Ü–∏—è
        first_trade_size = float(first_trades[0].get("size", 0))
        first_trade_price = float(first_trades[0].get("price", 0))
        first_position_usd = first_trade_size * first_trade_price
        
        if first_position_usd >= self.min_position_size:
            patterns.append({
                "type": "new_wallet_large_position",
                "size": first_position_usd,
                "description": f"New wallet opened large position: ${first_position_usd:,.0f}"
            })
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –í—ã—Å–æ–∫–∏–π win rate –Ω–∞ –ø–µ—Ä–≤—ã—Ö —Å–¥–µ–ª–∫–∞—Ö
        closed_positions = get_closed_positions(wallet_address, limit=10)
        if len(closed_positions) >= 3:
            wins = sum([1 for p in closed_positions if float(p.get("realizedPnl", 0)) > 0])
            win_rate = wins / len(closed_positions)
            
            if win_rate >= self.min_win_rate:
                patterns.append({
                    "type": "high_winrate_new_wallet",
                    "win_rate": win_rate,
                    "trades": len(closed_positions),
                    "description": f"New wallet with {win_rate:.1%} win rate on first {len(closed_positions)} trades"
                })
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è
        markets_traded = set()
        for trade in first_trades:
            condition_id = trade.get("condition_id")
            if condition_id:
                markets_traded.add(condition_id)
        
        if len(markets_traded) == 1 and len(first_trades) >= 5:
            patterns.append({
                "type": "concentrated_trading",
                "market": list(markets_traded)[0],
                "trades": len(first_trades),
                "description": f"New wallet trading only one market: {len(first_trades)} trades"
            })
        
        if patterns:
            return {
                "wallet": wallet_address,
                "patterns": patterns,
                "risk_level": "high" if len(patterns) >= 2 else "medium"
            }
        
        return None
```

---

## 7. Category-Specific Consensus

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å –≤ —Ä–∞–º–∫–∞—Ö –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ä—ã–Ω–∫–æ–≤ (Politics, Sports, Crypto –∏ —Ç.–¥.).

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**: –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ä—ã–Ω–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å –ø–æ–º–æ—â—å—é ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
2. **–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
3. **–ö–æ–Ω—Å–µ–Ω—Å—É—Å**: –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å —Å—Ä–µ–¥–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
4. **–†–æ—É—Ç–∏–Ω–≥**: –ù–∞–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ –∫–∞–Ω–∞–ª—ã

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Gamma API - Market Metadata

```python
# –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä—ã–Ω–∫–µ –≤–∫–ª—é—á–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—é
GET https://gamma-api.polymarket.com/events
Parameters:
  - conditionId: condition_id

def get_market_category(condition_id: str):
    url = "https://gamma-api.polymarket.com/events"
    params = {"conditionId": condition_id}
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        data = response.json()
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö
        category = (data.get("category") or 
                   data.get("group") or 
                   data.get("tags", [{}])[0].get("name") if data.get("tags") else None)
        return category
    return None
```

#### 2. ML –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞)

```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑ ml_classifier.py
from ml_classifier import classify_market

def classify_market_category(event_data: dict, slug: str = None, question: str = None):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ä—ã–Ω–æ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    category = classify_market(event_data, slug, question)
    return category
```

#### 3. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¢—Ä–µ–π–¥–µ—Ä–æ–≤

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
CREATE TABLE trader_category_performance (
    wallet_address TEXT,
    category TEXT,
    markets_traded INTEGER,
    win_rate REAL,
    total_volume REAL,
    total_profit REAL,
    PRIMARY KEY (wallet_address, category)
);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class CategoryConsensusDetector:
    def __init__(self, db, ml_classifier):
        self.db = db
        self.ml_classifier = ml_classifier
    
    def detect_category_consensus(self, condition_id: str, outcome_index: int, 
                                 wallets: List[str]):
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ä—ã–Ω–æ–∫
        event_data = get_event_data(condition_id)
        category = self.ml_classifier.classify_market(
            event_data, 
            slug=event_data.get("slug"),
            question=event_data.get("question")
        )
        
        if not category:
            return None
        
        # –ü–æ–ª—É—á–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Ç—Ä–µ–π–¥–µ—Ä—ã —Å –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
        category_experts = self._get_category_experts(category, min_markets=5)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–∫–æ–ª—å–∫–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–µ
        expert_wallets = [w for w in wallets if w in category_experts]
        
        if len(expert_wallets) >= 2:
            return {
                "category": category,
                "expert_count": len(expert_wallets),
                "expert_wallets": expert_wallets,
                "total_consensus": len(wallets),
                "strength": "strong" if len(expert_wallets) >= 3 else "moderate"
            }
        
        return None
    
    def _get_category_experts(self, category: str, min_markets: int = 5) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT wallet_address
                FROM trader_category_performance
                WHERE category = ?
                  AND markets_traded >= ?
                  AND win_rate >= 0.70
                ORDER BY total_profit DESC
                LIMIT 50
            """, (category, min_markets))
            
            rows = cursor.fetchall()
            return [row[0] for row in rows]
```

---

## 8. Size-Based Signal Routing

### –û–ø–∏—Å–∞–Ω–∏–µ

–ù–∞–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. –†–∞–∑–¥–µ–ª—è–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —É—Ä–æ–≤–Ω—é —É–±–µ–∂–¥–µ–Ω–∏—è —Ç—Ä–µ–π–¥–µ—Ä–æ–≤.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞**: –í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π USD —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –≤—Å–µ—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –≤ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–µ
2. **–†–æ—É—Ç–∏–Ω–≥**: –ù–∞–ø—Ä–∞–≤–ª—è–µ—Ç –≤ —Ä–∞–∑–Ω—ã–µ Telegram —Ç–æ–ø–∏–∫–∏:
   - Low Size (<$10K): –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
   - High Size (‚â•$10K): –ü—Ä–µ–º–∏—É–º —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤
3. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –ü–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞
4. **–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è**: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –æ—á–µ–Ω—å –∫—Ä—É–ø–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Polymarket Data API - –ê–∫—Ç–∏–≤–Ω—ã–µ –ü–æ–∑–∏—Ü–∏–∏

```python
# –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞
GET https://data-api.polymarket.com/positions
Parameters:
  - user: wallet_address
  - market: condition_id (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

def get_wallet_position_size(wallet_address: str, condition_id: str, 
                             outcome_index: int) -> float:
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞"""
    url = "https://data-api.polymarket.com/positions"
    params = {
        "user": wallet_address,
        "market": condition_id
    }
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        positions = response.json()
        for pos in positions:
            if (pos.get("condition_id") == condition_id and 
                pos.get("outcome_index") == outcome_index):
                return float(pos.get("size", 0))
    return 0.0
```

#### 2. Polymarket Data API - –ò—Å—Ç–æ—Ä–∏—è –°–¥–µ–ª–æ–∫

```python
# –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞
GET https://data-api.polymarket.com/trades
Parameters:
  - user: wallet_address
  - market: condition_id
  - side: BUY –∏–ª–∏ SELL
  - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫

def get_wallet_entry_price(wallet_address: str, condition_id: str, 
                           outcome_index: int, side: str = "BUY") -> float:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ä–µ–¥–Ω—é—é —Ü–µ–Ω—É –≤—Ö–æ–¥–∞ –∫–æ—à–µ–ª—å–∫–∞"""
    url = "https://data-api.polymarket.com/trades"
    params = {
        "user": wallet_address,
        "market": condition_id,
        "side": side,
        "limit": 10
    }
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        trades = response.json()
        if trades:
            prices = [float(t.get("price", 0)) for t in trades]
            return sum(prices) / len(prices) if prices else 0.0
    return 0.0
```

#### 3. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ò—Å—Ç–æ—Ä–∏—è –ü–æ–∑–∏—Ü–∏–π

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–æ–∑–∏—Ü–∏–π
CREATE TABLE signal_position_sizes (
    signal_id INTEGER,
    wallet_address TEXT,
    condition_id TEXT,
    outcome_index INTEGER,
    position_size REAL,
    entry_price REAL,
    usd_value REAL,
    PRIMARY KEY (signal_id, wallet_address),
    FOREIGN KEY (signal_id) REFERENCES signals(id)
);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class SizeBasedRouter:
    def __init__(self, db, size_threshold_usd=10000, 
                 very_high_size_threshold=50000):
        self.db = db
        self.size_threshold_usd = size_threshold_usd
        self.very_high_size_threshold = very_high_size_threshold
    
    def calculate_total_position_size(self, wallets: List[str], 
                                     wallet_prices: Dict[str, float],
                                     condition_id: str, 
                                     outcome_index: int) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –≤ USD"""
        total_usd = 0.0
        
        for wallet in wallets:
            # –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –∫–æ—à–µ–ª—å–∫–∞
            position_size = get_wallet_position_size(
                wallet, condition_id, outcome_index
            )
            
            # –ü–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É –≤—Ö–æ–¥–∞ (–∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–ª–∏ –∏–∑ API)
            entry_price = wallet_prices.get(wallet, 0.0)
            
            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞, –ø–æ–ª—É—á–∏—Ç—å –∏–∑ API
            if entry_price == 0.0:
                entry_price = get_wallet_entry_price(
                    wallet, condition_id, outcome_index
                )
            
            # USD —Å—Ç–æ–∏–º–æ—Å—Ç—å = —Ä–∞–∑–º–µ—Ä * —Ü–µ–Ω–∞
            if entry_price > 0 and position_size > 0:
                usd_value = position_size * entry_price
                total_usd += usd_value
        
        return total_usd
    
    def route_signal(self, total_usd: float, wallets: List[str],
                    condition_id: str, outcome_index: int,
                    signal_id: int = None) -> dict:
        """–ù–∞–ø—Ä–∞–≤–∏—Ç—å —Å–∏–≥–Ω–∞–ª –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–æ–ø–∏–∫ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é"""
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ä–∞–∑–º–µ—Ä–∞
        if total_usd >= self.very_high_size_threshold:
            size_category = "very_high"
            topic_id = "very_high_size"  # –û—á–µ–Ω—å –∫—Ä—É–ø–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
            priority = "highest"
        elif total_usd >= self.size_threshold_usd:
            size_category = "high"
            topic_id = "high_size"  # –ü—Ä–µ–º–∏—É–º —Ç–æ–ø–∏–∫
            priority = "high"
        else:
            size_category = "low"
            topic_id = "low_size"  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ç–æ–ø–∏–∫
            priority = "normal"
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–∞—Ö –ø–æ–∑–∏—Ü–∏–π –≤ –ë–î
        if signal_id:
            self._save_position_sizes(
                signal_id, wallets, condition_id, outcome_index,
                wallet_prices={}, total_usd=total_usd
            )
        
        return {
            "size_category": size_category,
            "total_usd": total_usd,
            "topic_id": topic_id,
            "priority": priority,
            "wallet_count": len(wallets),
            "avg_position_size": total_usd / len(wallets) if wallets else 0
        }
    
    def _save_position_sizes(self, signal_id: int, wallets: List[str],
                             condition_id: str, outcome_index: int,
                             wallet_prices: Dict[str, float],
                             total_usd: float):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä—ã –ø–æ–∑–∏—Ü–∏–π –≤ –ë–î"""
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            
            for wallet in wallets:
                position_size = get_wallet_position_size(
                    wallet, condition_id, outcome_index
                )
                entry_price = wallet_prices.get(wallet, 0.0)
                
                if entry_price == 0.0:
                    entry_price = get_wallet_entry_price(
                        wallet, condition_id, outcome_index
                    )
                
                usd_value = position_size * entry_price if entry_price > 0 else 0
                
                cursor.execute("""
                    INSERT OR REPLACE INTO signal_position_sizes
                    (signal_id, wallet_address, condition_id, outcome_index,
                     position_size, entry_price, usd_value)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (signal_id, wallet, condition_id, outcome_index,
                      position_size, entry_price, usd_value))
            
            conn.commit()
    
    def get_size_statistics(self, days: int = 7) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –ø–æ–∑–∏—Ü–∏–π"""
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_signals,
                    SUM(CASE WHEN usd_value < ? THEN 1 ELSE 0 END) as low_size,
                    SUM(CASE WHEN usd_value >= ? AND usd_value < ? THEN 1 ELSE 0 END) as high_size,
                    SUM(CASE WHEN usd_value >= ? THEN 1 ELSE 0 END) as very_high_size,
                    AVG(usd_value) as avg_size,
                    MAX(usd_value) as max_size
                FROM signal_position_sizes
                WHERE signal_id IN (
                    SELECT id FROM signals WHERE created_at >= ?
                )
            """, (self.size_threshold_usd, self.size_threshold_usd,
                  self.very_high_size_threshold, self.very_high_size_threshold,
                  cutoff_date.isoformat()))
            
            row = cursor.fetchone()
            return {
                "total_signals": row[0],
                "low_size_count": row[1],
                "high_size_count": row[2],
                "very_high_size_count": row[3],
                "avg_size": row[4] or 0,
                "max_size": row[5] or 0
            }
```

---

## 9. Multi-Timeframe Consensus

### –û–ø–∏—Å–∞–Ω–∏–µ

–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–Ω–∞—Ö (5–º–∏–Ω, 15–º–∏–Ω, 1—á) –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ –ø–æ–≤—ã—à–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω –Ω–∞ —Ä—ã–Ω–æ–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
2. **–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤**: –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö
3. **–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å**: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
4. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è**: –§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ —Å–∏–≥–Ω–∞–ª—ã –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏
5. **–í–∞–ª–∏–¥–∞—Ü–∏—è**: –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–∞ –º–∏–Ω–∏–º—É–º 2 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –û–∫–Ω–∞

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–æ–≤ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
CREATE TABLE timeframe_consensus (
    condition_id TEXT,
    outcome_index INTEGER,
    side TEXT,
    timeframe_minutes INTEGER,
    wallet_count INTEGER,
    consensus_detected_at TEXT,
    PRIMARY KEY (condition_id, outcome_index, side, timeframe_minutes, consensus_detected_at)
);

# –ò–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX idx_timeframe_consensus ON timeframe_consensus(
    condition_id, outcome_index, side, timeframe_minutes, consensus_detected_at
);
```

#### 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ConsensusDetector –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞

```python
# –ö–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–≤–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä ConsensusDetector
# —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º window_minutes
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class MultiTimeframeConsensus:
    def __init__(self, db, timeframes: List[int] = [5, 15, 60], min_consensus=3):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä –º—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
        
        Args:
            db: –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
            timeframes: –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –≤ –º–∏–Ω—É—Ç–∞—Ö [5, 15, 60]
            min_consensus: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—à–µ–ª—å–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
        """
        self.db = db
        self.timeframes = timeframes
        self.min_consensus = min_consensus
        
        # –°–æ–∑–¥–∞—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        self.consensus_detectors = {}
        for tf in timeframes:
            self.consensus_detectors[tf] = ConsensusDetector(
                db=db,
                window_minutes=tf,
                min_consensus=min_consensus
            )
    
    def process_trade(self, wallet_address: str, condition_id: str,
                     outcome_index: int, side: str, price: float,
                     timestamp: datetime):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–¥–µ–ª–∫—É –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
        results = {}
        
        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–¥–µ–ª–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        for timeframe, detector in self.consensus_detectors.items():
            result = detector.process_trade(
                wallet_address, condition_id, outcome_index,
                side, price, timestamp
            )
            results[timeframe] = result
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å
        return self._check_multi_timeframe_consensus(
            condition_id, outcome_index, side, results
        )
    
    def _check_multi_timeframe_consensus(self, condition_id: str,
                                        outcome_index: int, side: str,
                                        timeframe_results: Dict[int, any]) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö"""
        confirmed_timeframes = []
        timeframe_details = {}
        
        for timeframe, result in timeframe_results.items():
            if result:  # –ï—Å–ª–∏ –∫–æ–Ω—Å–µ–Ω—Å—É—Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–∞ —ç—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ
                confirmed_timeframes.append(timeframe)
                timeframe_details[timeframe] = {
                    "wallet_count": result.get("wallet_count", 0),
                    "total_position_usd": result.get("total_position_usd", 0),
                    "detected_at": result.get("timestamp")
                }
        
        # –¢—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 2 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        if len(confirmed_timeframes) >= 2:
            # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = self._calculate_confidence(
                confirmed_timeframes, timeframe_details
            )
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
            self._save_multi_timeframe_consensus(
                condition_id, outcome_index, side,
                confirmed_timeframes, timeframe_details, confidence
            )
            
            return {
                "confirmed": True,
                "timeframes": confirmed_timeframes,
                "timeframe_details": timeframe_details,
                "confidence": confidence,
                "consensus_strength": self._calculate_strength(timeframe_details)
            }
        
        return None
    
    def _calculate_confidence(self, confirmed_timeframes: List[int],
                             timeframe_details: Dict[int, dict]) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
        # –ï—Å–ª–∏ –≤—Å–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã - –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if len(confirmed_timeframes) == len(self.timeframes):
            return "very_high"
        
        # –ï—Å–ª–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã (15–º–∏–Ω, 60–º–∏–Ω) - –≤—ã—Å–æ–∫–∞—è
        if 15 in confirmed_timeframes and 60 in confirmed_timeframes:
            return "high"
        
        # –ï—Å–ª–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã —Å—Ä–µ–¥–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã (5–º–∏–Ω, 15–º–∏–Ω) - —Å—Ä–µ–¥–Ω—è—è
        if 5 in confirmed_timeframes and 15 in confirmed_timeframes:
            return "medium"
        
        # –ò–Ω–∞—á–µ - –Ω–∏–∑–∫–∞—è
        return "low"
    
    def _calculate_strength(self, timeframe_details: Dict[int, dict]) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Å–∏–ª—É –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞"""
        total_wallets = sum([d["wallet_count"] for d in timeframe_details.values()])
        total_position = sum([d["total_position_usd"] for d in timeframe_details.values()])
        
        if total_wallets >= 6 and total_position >= 20000:
            return "very_strong"
        elif total_wallets >= 4 and total_position >= 10000:
            return "strong"
        elif total_wallets >= 3:
            return "moderate"
        else:
            return "weak"
    
    def _save_multi_timeframe_consensus(self, condition_id: str,
                                       outcome_index: int, side: str,
                                       confirmed_timeframes: List[int],
                                       timeframe_details: Dict[int, dict],
                                       confidence: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å –≤ –ë–î"""
        timestamp = datetime.now(timezone.utc).isoformat()
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            
            for timeframe in confirmed_timeframes:
                details = timeframe_details[timeframe]
                cursor.execute("""
                    INSERT INTO timeframe_consensus
                    (condition_id, outcome_index, side, timeframe_minutes,
                     wallet_count, consensus_detected_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (condition_id, outcome_index, side, timeframe,
                      details["wallet_count"], timestamp))
            
            conn.commit()
    
    def get_multi_timeframe_statistics(self, days: int = 7) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∫–æ–Ω—Å–µ–Ω—Å—É—Å–æ–≤"""
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT condition_id || ':' || outcome_index || ':' || side) as total_signals,
                    AVG(wallet_count) as avg_wallet_count,
                    COUNT(CASE WHEN timeframe_minutes = 5 THEN 1 END) as tf_5min_count,
                    COUNT(CASE WHEN timeframe_minutes = 15 THEN 1 END) as tf_15min_count,
                    COUNT(CASE WHEN timeframe_minutes = 60 THEN 1 END) as tf_60min_count
                FROM timeframe_consensus
                WHERE consensus_detected_at >= ?
            """, (cutoff_date.isoformat(),))
            
            row = cursor.fetchone()
            return {
                "total_signals": row[0] or 0,
                "avg_wallet_count": row[1] or 0,
                "tf_5min_signals": row[2] or 0,
                "tf_15min_signals": row[3] or 0,
                "tf_60min_signals": row[4] or 0
            }
    
    def detect_multi_timeframe_consensus(self, condition_id: str,
                                        outcome_index: int, side: str) -> dict:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)"""
        timeframe_results = {}
        
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–¥–µ–ª–∫–∏ –ø–æ —ç—Ç–æ–º—É —Ä—ã–Ω–∫—É –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        all_trades = self._get_recent_trades(condition_id, outcome_index, side, hours=1)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        for timeframe, detector in self.consensus_detectors.items():
            # –û—á–∏—Å—Ç–∏—Ç—å –æ–∫–Ω–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
            detector.rolling_windows.clear()
            
            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Å–¥–µ–ª–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            for trade in all_trades:
                result = detector.process_trade(
                    trade["wallet"],
                    condition_id,
                    outcome_index,
                    side,
                    trade["price"],
                    trade["timestamp"]
                )
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Å–µ–Ω—Å—É—Å
            key = f"{condition_id}:{outcome_index}:{side}"
            window = detector.rolling_windows.get(key, {})
            wallet_count = len(set(window.get("wallets", [])))
            
            timeframe_results[timeframe] = {
                "has_consensus": wallet_count >= self.min_consensus,
                "wallet_count": wallet_count,
                "wallets": list(set(window.get("wallets", [])))
            }
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        consensus_count = sum([
            1 for r in timeframe_results.values() 
            if r["has_consensus"]
        ])
        
        if consensus_count >= 2:
            confirmed_timeframes = [
                tf for tf, r in timeframe_results.items()
                if r["has_consensus"]
            ]
            
            return {
                "confirmed": True,
                "timeframes": confirmed_timeframes,
                "timeframe_details": {
                    tf: {
                        "wallet_count": timeframe_results[tf]["wallet_count"],
                        "wallets": timeframe_results[tf]["wallets"]
                    }
                    for tf in confirmed_timeframes
                },
                "confidence": "high" if consensus_count == 3 else "medium"
            }
        
        return None
    
    def _get_recent_trades(self, condition_id: str, outcome_index: int,
                          side: str, hours: int = 1) -> List[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–µ–¥–∞–≤–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –ø–æ —Ä—ã–Ω–∫—É"""
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –∫–æ—à–µ–ª—å–∫–∏
        tracked_wallets = self.db.get_tracked_wallets()
        
        all_trades = []
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours)
        
        for wallet in tracked_wallets:
            trades = get_wallet_trades(wallet, side=side, limit=100)
            for trade in trades:
                if (trade.get("condition_id") == condition_id and
                    trade.get("outcome_index") == outcome_index):
                    trade_time = datetime.fromisoformat(
                        trade.get("timestamp", "").replace("Z", "+00:00")
                    )
                    if trade_time >= cutoff_time:
                        all_trades.append({
                            "wallet": wallet,
                            "price": float(trade.get("price", 0)),
                            "timestamp": trade_time
                        })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        all_trades.sort(key=lambda x: x["timestamp"])
        return all_trades
```

---

## 10. News Correlation Signals

### –û–ø–∏—Å–∞–Ω–∏–µ

–ö–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å –Ω–æ–≤–æ—Å—Ç–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ –∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤.

### –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç

1. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π**: –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å –Ω–æ–≤–æ—Å—Ç–Ω—ã–º–∏ API (Alpha Vantage, NewsAPI, custom sources)
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Ü—Å–µ—Ç–µ–π**: –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö (Twitter/X, Reddit)
3. **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è**: –ö–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è —Å —Ç–æ—Ä–≥–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é
4. **–ö–æ–Ω—Ç–µ–∫—Å—Ç**: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
5. **–í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑**: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–æ –∏ –ø–æ—Å–ª–µ –Ω–æ–≤–æ—Å—Ç–µ–π
6. **Sentiment –∞–Ω–∞–ª–∏–∑**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π

### –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –î–∞–Ω–Ω—ã—Ö

#### 1. Alpha Vantage News API

```python
# –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
GET https://www.alphavantage.co/query
Parameters:
  - function: NEWS_SENTIMENT
  - apikey: your_api_key
  - topics: topic_keywords (comma-separated)
  - time_from: start_time (YYYYMMDDTHHMM format)
  - time_to: end_time (YYYYMMDDTHHMM format)
  - limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π (default: 50)

def get_news_for_market(market_keywords: List[str], hours: int = 24, limit: int = 50):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Ä—ã–Ω–∫–∞"""
    url = "https://www.alphavantage.co/query"
    params = {
        "function": "NEWS_SENTIMENT",
        "apikey": os.getenv("ALPHA_VANTAGE_API_KEY"),
        "topics": ",".join(market_keywords),
        "time_from": (datetime.now(timezone.utc) - timedelta(hours=hours)).strftime("%Y%m%dT%H%M"),
        "time_to": datetime.now(timezone.utc).strftime("%Y%m%dT%H%M"),
        "limit": limit
    }
    response = requests.get(url, params=params, timeout=10)
    
    if response.status_code == 200:
        data = response.json()
        return data.get("feed", [])
    return []
```

#### 2. NewsAPI (–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫)

```python
# –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ NewsAPI
GET https://newsapi.org/v2/everything
Parameters:
  - q: search query
  - apiKey: your_api_key
  - from: start_date (ISO 8601)
  - to: end_date (ISO 8601)
  - sortBy: relevance, popularity, publishedAt
  - language: en

def get_newsapi_news(query: str, hours: int = 24):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ NewsAPI"""
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": query,
        "apiKey": os.getenv("NEWSAPI_KEY"),
        "from": (datetime.now(timezone.utc) - timedelta(hours=hours)).isoformat(),
        "to": datetime.now(timezone.utc).isoformat(),
        "sortBy": "relevance",
        "language": "en"
    }
    response = requests.get(url, params=params, timeout=10)
    
    if response.status_code == 200:
        data = response.json()
        return data.get("articles", [])
    return []
```

#### 3. Twitter/X API v2

```python
# –ü–æ–∏—Å–∫ —Ç–≤–∏—Ç–æ–≤ —á–µ—Ä–µ–∑ Twitter API v2
GET https://api.twitter.com/2/tweets/search/recent
Headers:
  Authorization: Bearer {bearer_token}
Parameters:
  - query: search query
  - max_results: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (10-100)
  - start_time: start time (ISO 8601)
  - end_time: end time (ISO 8601)

def search_tweets(query: str, count: int = 100, hours: int = 24):
    """–ü–æ–∏—Å–∫ —Ç–≤–∏—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
    url = "https://api.twitter.com/2/tweets/search/recent"
    headers = {
        "Authorization": f"Bearer {os.getenv('TWITTER_BEARER_TOKEN')}"
    }
    params = {
        "query": query,
        "max_results": min(count, 100),
        "start_time": (datetime.now(timezone.utc) - timedelta(hours=hours)).isoformat(),
        "tweet.fields": "created_at,public_metrics,author_id",
        "expansions": "author_id"
    }
    
    response = requests.get(url, headers=headers, params=params, timeout=10)
    
    if response.status_code == 200:
        data = response.json()
        return data.get("data", [])
    return []
```

#### 4. Reddit API (—á–µ—Ä–µ–∑ PRAW –∏–ª–∏ Reddit API)

```python
# –ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ –≤ Reddit
import praw

def search_reddit_posts(query: str, subreddit: str = None, limit: int = 50):
    """–ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ –≤ Reddit"""
    reddit = praw.Reddit(
        client_id=os.getenv("REDDIT_CLIENT_ID"),
        client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
        user_agent="PolyEye/1.0"
    )
    
    if subreddit:
        sub = reddit.subreddit(subreddit)
        posts = sub.search(query, limit=limit, sort="relevance", time_filter="day")
    else:
        posts = reddit.subreddit("all").search(query, limit=limit, sort="relevance", time_filter="day")
    
    return [{
        "title": post.title,
        "score": post.score,
        "created_utc": datetime.fromtimestamp(post.created_utc, tz=timezone.utc),
        "url": post.url,
        "subreddit": post.subreddit.display_name
    } for post in posts]
```

#### 5. –ë–∞–∑–∞ –î–∞–Ω–Ω—ã—Ö - –ò—Å—Ç–æ—Ä–∏—è –ù–æ–≤–æ—Å—Ç–µ–π

```python
# –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
CREATE TABLE news_correlations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    signal_id INTEGER,
    condition_id TEXT,
    news_source TEXT,
    news_title TEXT,
    news_url TEXT,
    news_published_at TEXT,
    sentiment_score REAL,
    correlation_type TEXT,  -- 'before', 'after', 'during'
    social_mentions_count INTEGER,
    created_at TEXT,
    FOREIGN KEY (signal_id) REFERENCES signals(id)
);

CREATE INDEX idx_news_condition ON news_correlations(condition_id, news_published_at);
```

### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
class NewsCorrelationAnalyzer:
    def __init__(self, db):
        self.db = db
        self.news_sources = ["alphavantage", "newsapi"]  # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        self.social_sources = ["twitter", "reddit"]  # –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    
    def correlate_with_news(self, condition_id: str, consensus_signal: dict,
                           signal_id: int = None) -> dict:
        """–ö–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º–∏ –º–µ–¥–∏–∞"""
        # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä—ã–Ω–∫–µ
        market_info = get_market_info(condition_id)
        if not market_info:
            return None
        
        # –ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ä—ã–Ω–∫–∞
        keywords = self._extract_keywords(market_info)
        
        # –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        all_news = []
        for source in self.news_sources:
            if source == "alphavantage":
                news = get_news_for_market(keywords, hours=24)
                all_news.extend(news)
            elif source == "newsapi":
                query = " ".join(keywords)
                news = get_newsapi_news(query, hours=24)
                all_news.extend(news)
        
        # –ü–æ–ª—É—á–∏—Ç—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
        social_data = {}
        query = " ".join(keywords)
        
        if "twitter" in self.social_sources:
            tweets = search_tweets(query, count=100, hours=24)
            social_data["twitter"] = {
                "count": len(tweets),
                "tweets": tweets[:10]  # –¢–æ–ø 10 —Ç–≤–∏—Ç–æ–≤
            }
        
        if "reddit" in self.social_sources:
            reddit_posts = search_reddit_posts(query, limit=50)
            social_data["reddit"] = {
                "count": len(reddit_posts),
                "posts": reddit_posts[:10]  # –¢–æ–ø 10 –ø–æ—Å—Ç–æ–≤
            }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
        signal_time = datetime.fromisoformat(
            consensus_signal.get("timestamp", datetime.now(timezone.utc).isoformat())
            .replace("Z", "+00:00")
        )
        
        temporal_analysis = self._analyze_temporal_correlation(
            signal_time, all_news, social_data
        )
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å sentiment
        sentiment_analysis = self._analyze_sentiment(all_news, social_data)
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π correlation score
        correlation_score = self._calculate_correlation_score(
            consensus_signal, all_news, social_data, temporal_analysis, sentiment_analysis
        )
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
        if signal_id:
            self._save_news_correlation(
                signal_id, condition_id, all_news, social_data,
                correlation_score, temporal_analysis
            )
        
        return {
            "correlation_score": correlation_score,
            "news_count": len(all_news),
            "social_mentions": {
                "twitter": social_data.get("twitter", {}).get("count", 0),
                "reddit": social_data.get("reddit", {}).get("count", 0)
            },
            "temporal_analysis": temporal_analysis,
            "sentiment_analysis": sentiment_analysis,
            "recent_news": sorted(all_news, key=lambda x: x.get("published_at", ""), reverse=True)[:5],
            "top_social": {
                "twitter": social_data.get("twitter", {}).get("tweets", [])[:3],
                "reddit": social_data.get("reddit", {}).get("posts", [])[:3]
            }
        }
    
    def _extract_keywords(self, market_info: dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä—ã–Ω–∫–µ"""
        keywords = []
        
        # –ò–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ä—ã–Ω–∫–∞
        title = market_info.get("title", "")
        if title:
            # –£–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∏–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            stop_words = {"will", "be", "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with"}
            words = title.lower().split()
            keywords.extend([w for w in words if w not in stop_words and len(w) > 2])
        
        # –ò–∑ –≤–æ–ø—Ä–æ—Å–∞ —Ä—ã–Ω–∫–∞
        question = market_info.get("question", "")
        if question:
            words = question.lower().split()
            keywords.extend([w for w in words if w not in stop_words and len(w) > 2])
        
        # –ò–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category = market_info.get("category", "")
        if category:
            keywords.append(category.lower())
        
        # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–µ—Ä–Ω—É—Ç—å
        return list(set(keywords))[:10]  # –ú–∞–∫—Å–∏–º—É–º 10 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    
    def _analyze_temporal_correlation(self, signal_time: datetime,
                                     news: List[dict], social_data: dict) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É —Å–∏–≥–Ω–∞–ª–æ–º –∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏"""
        before_count = 0
        after_count = 0
        during_count = 0
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        for article in news:
            published_at = self._parse_news_time(article)
            if not published_at:
                continue
            
            time_diff = (signal_time - published_at).total_seconds() / 3600  # –í —á–∞—Å–∞—Ö
            
            if time_diff < -1:  # –ù–æ–≤–æ—Å—Ç—å –ø–æ—Å–ª–µ —Å–∏–≥–Ω–∞–ª–∞
                after_count += 1
            elif time_diff > 1:  # –ù–æ–≤–æ—Å—Ç—å –¥–æ —Å–∏–≥–Ω–∞–ª–∞
                before_count += 1
            else:  # –ù–æ–≤–æ—Å—Ç—å –≤–æ –≤—Ä–µ–º—è —Å–∏–≥–Ω–∞–ª–∞ (¬±1 —á–∞—Å)
                during_count += 1
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏–∞
        for source, data in social_data.items():
            items = data.get("tweets", []) or data.get("posts", [])
            for item in items:
                created_at = self._parse_social_time(item, source)
                if not created_at:
                    continue
                
                time_diff = (signal_time - created_at).total_seconds() / 3600
                
                if time_diff < -1:
                    after_count += 1
                elif time_diff > 1:
                    before_count += 1
                else:
                    during_count += 1
        
        return {
            "before_signal": before_count,
            "during_signal": during_count,
            "after_signal": after_count,
            "total": before_count + during_count + after_count,
            "correlation_type": self._determine_correlation_type(
                before_count, during_count, after_count
            )
        }
    
    def _determine_correlation_type(self, before: int, during: int, after: int) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
        if before > during and before > after:
            return "pre_news_activity"  # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ—Å—Ç—è–º–∏
        elif during > before and during > after:
            return "news_driven"  # –î–≤–∏–∂–∏–º–æ –Ω–æ–≤–æ—Å—Ç—è–º–∏
        elif after > before and after > during:
            return "post_news_confirmation"  # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–æ–≤–æ—Å—Ç–µ–π
        else:
            return "mixed"  # –°–º–µ—à–∞–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
    
    def _analyze_sentiment(self, news: List[dict], social_data: dict) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å sentiment –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏–∞"""
        # –ü—Ä–æ—Å—Ç–æ–π sentiment –∞–Ω–∞–ª–∏–∑ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é NLP –±–∏–±–ª–∏–æ—Ç–µ–∫)
        positive_keywords = ["up", "rise", "gain", "bullish", "positive", "good", "strong", "win"]
        negative_keywords = ["down", "fall", "drop", "bearish", "negative", "bad", "weak", "lose"]
        
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        for article in news:
            text = (article.get("title", "") + " " + article.get("summary", "")).lower()
            pos_score = sum([1 for kw in positive_keywords if kw in text])
            neg_score = sum([1 for kw in negative_keywords if kw in text])
            
            if pos_score > neg_score:
                positive_count += 1
            elif neg_score > pos_score:
                negative_count += 1
            else:
                neutral_count += 1
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏–∞
        for source, data in social_data.items():
            items = data.get("tweets", []) or data.get("posts", [])
            for item in items:
                text = (item.get("text", "") or item.get("title", "")).lower()
                pos_score = sum([1 for kw in positive_keywords if kw in text])
                neg_score = sum([1 for kw in negative_keywords if kw in text])
                
                if pos_score > neg_score:
                    positive_count += 1
                elif neg_score > pos_score:
                    negative_count += 1
                else:
                    neutral_count += 1
        
        total = positive_count + negative_count + neutral_count
        if total == 0:
            return {"sentiment": "neutral", "score": 0.0}
        
        sentiment_score = (positive_count - negative_count) / total
        
        return {
            "sentiment": "positive" if sentiment_score > 0.2 else "negative" if sentiment_score < -0.2 else "neutral",
            "score": sentiment_score,
            "positive": positive_count,
            "negative": negative_count,
            "neutral": neutral_count
        }
    
    def _calculate_correlation_score(self, consensus_signal: dict,
                                     news: List[dict], social_data: dict,
                                     temporal_analysis: dict,
                                     sentiment_analysis: dict) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π correlation score (0.0 - 1.0)"""
        score = 0.0
        
        # –§–∞–∫—Ç–æ—Ä 1: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π (–º–∞–∫—Å–∏–º—É–º 0.3)
        news_factor = min(len(news) / 20.0, 1.0) * 0.3
        score += news_factor
        
        # –§–∞–∫—Ç–æ—Ä 2: –°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 0.2)
        social_count = sum([
            social_data.get("twitter", {}).get("count", 0),
            social_data.get("reddit", {}).get("count", 0)
        ])
        social_factor = min(social_count / 100.0, 1.0) * 0.2
        score += social_factor
        
        # –§–∞–∫—Ç–æ—Ä 3: –í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–º–∞–∫—Å–∏–º—É–º 0.3)
        total_temporal = temporal_analysis["total"]
        if total_temporal > 0:
            temporal_factor = min(total_temporal / 30.0, 1.0) * 0.3
            score += temporal_factor
        
        # –§–∞–∫—Ç–æ—Ä 4: Sentiment —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–º–∞–∫—Å–∏–º—É–º 0.2)
        # –ï—Å–ª–∏ sentiment –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∏ —Å–∏–≥–Ω–∞–ª BUY, –∏–ª–∏ negative –∏ —Å–∏–≥–Ω–∞–ª SELL
        signal_side = consensus_signal.get("side", "BUY")
        sentiment = sentiment_analysis.get("sentiment", "neutral")
        
        if (signal_side == "BUY" and sentiment == "positive") or \
           (signal_side == "SELL" and sentiment == "negative"):
            sentiment_factor = abs(sentiment_analysis.get("score", 0)) * 0.2
            score += sentiment_factor
        
        return min(score, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º—É–º 1.0
    
    def _parse_news_time(self, article: dict) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏—Ç—å –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏"""
        # –†–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        time_str = article.get("published_at") or article.get("time_published") or article.get("publishedAt")
        if not time_str:
            return None
        
        try:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            formats = [
                "%Y-%m-%dT%H:%M:%S%z",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y%m%dT%H%M",
                "%Y-%m-%d %H:%M:%S"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(time_str, fmt).replace(tzinfo=timezone.utc)
                except ValueError:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å ISO —Ñ–æ—Ä–º–∞—Ç
            return datetime.fromisoformat(time_str.replace("Z", "+00:00"))
        except Exception:
            return None
    
    def _parse_social_time(self, item: dict, source: str) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏—Ç—å –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø–æ—Å—Ç–∞"""
        if source == "twitter":
            time_str = item.get("created_at")
        elif source == "reddit":
            return datetime.fromtimestamp(item.get("created_utc", 0), tz=timezone.utc)
        else:
            return None
        
        if not time_str:
            return None
        
        try:
            return datetime.fromisoformat(time_str.replace("Z", "+00:00"))
        except Exception:
            return None
    
    def _save_news_correlation(self, signal_id: int, condition_id: str,
                               news: List[dict], social_data: dict,
                               correlation_score: float,
                               temporal_analysis: dict):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –≤ –ë–î"""
        timestamp = datetime.now(timezone.utc).isoformat()
        
        with self.db.get_connection() as conn:
            cursor = conn.cursor()
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å
            for article in news:
                published_at = self._parse_news_time(article)
                cursor.execute("""
                    INSERT INTO news_correlations
                    (signal_id, condition_id, news_source, news_title, news_url,
                     news_published_at, correlation_type, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    signal_id,
                    condition_id,
                    article.get("source", "unknown"),
                    article.get("title", "")[:500],  # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª–∏–Ω—É
                    article.get("url", ""),
                    published_at.isoformat() if published_at else None,
                    temporal_analysis.get("correlation_type", "mixed"),
                    timestamp
                ))
            
            conn.commit()
```

---

**–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–∞–π–ª–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...**
