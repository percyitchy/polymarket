#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Unknown —Ä—ã–Ω–∫–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
"""

import os
import sys
import logging
from collections import Counter, defaultdict
from typing import List, Dict, Any, Optional
import re
from dotenv import load_dotenv

sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from db import PolymarketDB
from wallet_analyzer import WalletAnalyzer
from market_utils import classify_market
from enhanced_market_data import enhance_market_data_for_classification

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def analyze_unknown_markets():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Unknown —Ä—ã–Ω–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    db = PolymarketDB()
    analyzer = WalletAnalyzer(db)
    
    print("=" * 80)
    print("üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó UNKNOWN –†–´–ù–ö–û–í")
    print("=" * 80)
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ—à–µ–ª—å–∫–∏ —Å Unknown –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
    with db.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT DISTINCT wallet_address
            FROM wallet_category_stats
            WHERE category = 'other/Unknown'
            LIMIT 500
        """)
        
        unknown_wallets = [row[0] for row in cursor.fetchall()]
        print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(unknown_wallets)} –∫–æ—à–µ–ª—å–∫–æ–≤ —Å Unknown –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏")
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ Unknown —Ä—ã–Ω–∫–∞—Ö
    all_unknown_markets = []
    processed_condition_ids = set()
    
    print(f"\nüì• –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ Unknown —Ä—ã–Ω–∫–∞—Ö...")
    
    for i, wallet_address in enumerate(unknown_wallets):
        if i % 50 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(unknown_wallets)} –∫–æ—à–µ–ª—å–∫–æ–≤...")
        
        try:
            closed_positions = analyzer._get_closed_positions(wallet_address)
            
            for position in closed_positions:
                condition_id = position.get("conditionId")
                if not condition_id or condition_id in processed_condition_ids:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ Unknown
                category_stats = db.get_wallet_category_stats(wallet_address, condition_id)
                if category_stats and category_stats.get("category") != "other/Unknown":
                    continue
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ä—ã–Ω–∫–∞
                slug = position.get("slug") or position.get("marketSlug") or position.get("eventSlug")
                question = position.get("title") or position.get("question") or position.get("marketTitle")
                description = position.get("description") or position.get("marketDescription")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º enhanced_market_data –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                try:
                    enhanced_data = enhance_market_data_for_classification(
                        condition_id=condition_id,
                        existing_slug=slug,
                        existing_question=question,
                        existing_description=description
                    )
                    
                    final_slug = enhanced_data.get("slug") or slug
                    final_question = enhanced_data.get("question") or question
                    final_description = enhanced_data.get("description") or description
                except Exception as e:
                    logger.debug(f"Error enhancing data for {condition_id[:20]}...: {e}")
                    final_slug = slug
                    final_question = question
                    final_description = description
                
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                combined_text = f"{final_question or ''} {final_description or ''} {final_slug or ''}".strip()
                
                # –ü–æ–≤—Ç–æ—Ä–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —ç—Ç–æ Unknown
                re_classified_category = classify_market({}, final_slug, combined_text)
                
                if re_classified_category == "other/Unknown":
                    all_unknown_markets.append({
                        "condition_id": condition_id,
                        "slug": final_slug,
                        "question": final_question,
                        "description": final_description,
                        "combined_text": combined_text,
                        "has_slug": bool(final_slug),
                        "has_question": bool(final_question),
                        "has_description": bool(final_description),
                        "text_length": len(combined_text)
                    })
                    processed_condition_ids.add(condition_id)
        except Exception as e:
            logger.debug(f"Error processing wallet {wallet_address[:20]}...: {e}")
            continue
    
    print(f"\n‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(all_unknown_markets)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö Unknown —Ä—ã–Ω–∫–æ–≤")
    
    if not all_unknown_markets:
        print("\n‚úÖ –í—Å–µ —Ä—ã–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã!")
        return
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    print("\n" + "=" * 80)
    print("üìä –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í")
    print("=" * 80)
    
    # 1. –ù–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    has_slug_count = sum(1 for m in all_unknown_markets if m["has_slug"])
    has_question_count = sum(1 for m in all_unknown_markets if m["has_question"])
    has_description_count = sum(1 for m in all_unknown_markets if m["has_description"])
    has_any_count = sum(1 for m in all_unknown_markets if m["has_slug"] or m["has_question"] or m["has_description"])
    empty_count = len(all_unknown_markets) - has_any_count
    
    print(f"\nüìã –ù–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   –ï—Å—Ç—å slug: {has_slug_count} ({has_slug_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –ï—Å—Ç—å question: {has_question_count} ({has_question_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –ï—Å—Ç—å description: {has_description_count} ({has_description_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –ï—Å—Ç—å –ª—é–±—ã–µ –¥–∞–Ω–Ω—ã–µ: {has_any_count} ({has_any_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ: {empty_count} ({empty_count/len(all_unknown_markets)*100:.1f}%)")
    
    # 2. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
    text_lengths = [m["text_length"] for m in all_unknown_markets]
    avg_length = sum(text_lengths) / len(text_lengths) if text_lengths else 0
    short_texts = [m for m in all_unknown_markets if m["text_length"] < 20]
    medium_texts = [m for m in all_unknown_markets if 20 <= m["text_length"] < 50]
    long_texts = [m for m in all_unknown_markets if m["text_length"] >= 50]
    
    print(f"\nüìè –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞:")
    print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_length:.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (<20): {len(short_texts)} ({len(short_texts)/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –°—Ä–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç (20-50): {len(medium_texts)} ({len(medium_texts)/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (>=50): {len(long_texts)} ({len(long_texts)/len(all_unknown_markets)*100:.1f}%)")
    
    # 3. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ
    date_patterns_count = 0
    price_patterns_count = 0
    question_patterns_count = 0
    number_patterns_count = 0
    
    keywords = Counter()
    stop_words = {
        "will", "the", "be", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
        "of", "with", "by", "from", "as", "is", "are", "was", "were", "been", "being",
        "this", "that", "it", "not", "no", "yes", "can", "do", "get", "has", "have", "had"
    }
    
    for market in all_unknown_markets:
        text = market["combined_text"].lower()
        
        # –î–∞—Ç—ã
        if re.search(r'\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}/\d{4}|january|february|march|april|may|june|july|august|september|october|november|december', text, re.IGNORECASE):
            date_patterns_count += 1
        
        # –¶–µ–Ω—ã
        if re.search(r'\$[\d,]+|\d+\.\d+%|\d+%|\d+[km]', text):
            price_patterns_count += 1
        
        # –í–æ–ø—Ä–æ—Å—ã
        if re.search(r'\b(will|is|are|does|can)\b.*\?', text):
            question_patterns_count += 1
        
        # –ß–∏—Å–ª–∞
        if re.search(r'\d+', text):
            number_patterns_count += 1
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        words = re.findall(r'\b\w+\b', text)
        for word in words:
            word_clean = word.strip(".,!?;:()[]{}'\"-").lower()
            if len(word_clean) > 2 and word_clean not in stop_words:
                keywords[word_clean] += 1
    
    print(f"\nüî§ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ:")
    print(f"   –° –¥–∞—Ç–∞–º–∏: {date_patterns_count} ({date_patterns_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –° —Ü–µ–Ω–∞–º–∏: {price_patterns_count} ({price_patterns_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –í–æ–ø—Ä–æ—Å—ã: {question_patterns_count} ({question_patterns_count/len(all_unknown_markets)*100:.1f}%)")
    print(f"   –° —á–∏—Å–ª–∞–º–∏: {number_patterns_count} ({number_patterns_count/len(all_unknown_markets)*100:.1f}%)")
    
    print(f"\nüìù –¢–æ–ø-30 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ Unknown —Ä—ã–Ω–∫–∞—Ö:")
    for word, count in keywords.most_common(30):
        print(f"   {word:<25} {count:>4}")
    
    # 4. –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã Unknown —Ä—ã–Ω–∫–æ–≤:")
    
    markets_with_data = [m for m in all_unknown_markets if m['has_question'] or m['has_slug']]
    print(f"\n1. –†—ã–Ω–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–æ Unknown ({len(markets_with_data)}):")
    samples_with_data = markets_with_data[:10]
    for i, market in enumerate(samples_with_data[:5], 1):
        print(f"   {i}. Slug: {market['slug'][:60] if market['slug'] else 'N/A'}")
        print(f"      Question: {market['question'][:80] if market['question'] else 'N/A'}")
        print(f"      Text length: {market['text_length']}")
    
    print(f"\n2. –†—ã–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ ({date_patterns_count}):")
    date_samples = [m for m in all_unknown_markets if re.search(r'\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}/\d{4}|january|february|march|april|may|june|july|august|september|october|november|december', m['combined_text'].lower(), re.IGNORECASE)][:5]
    for i, market in enumerate(date_samples, 1):
        print(f"   {i}. {market['question'][:80] or market['slug'][:80]}")
    
    print(f"\n3. –†—ã–Ω–∫–∏ —Å —Ü–µ–Ω–∞–º–∏ ({price_patterns_count}):")
    price_samples = [m for m in all_unknown_markets if re.search(r'\$[\d,]+|\d+\.\d+%|\d+%|\d+[km]', m['combined_text'])][:5]
    for i, market in enumerate(price_samples, 1):
        print(f"   {i}. {market['question'][:80] or market['slug'][:80]}")
    
    print(f"\n4. –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç ({len(short_texts)}):")
    for i, market in enumerate(short_texts[:5], 1):
        print(f"   {i}. {market['question'][:80] or market['slug'][:80] or 'N/A'} (length: {market['text_length']})")
    
    print(f"\n5. –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ ({empty_count}):")
    empty_samples = [m for m in all_unknown_markets if not (m["has_slug"] or m["has_question"] or m["has_description"])][:5]
    for i, market in enumerate(empty_samples, 1):
        print(f"   {i}. Condition ID: {market['condition_id'][:20]}... (no data)")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    import json
    with open("unknown_markets_analysis.json", "w") as f:
        json.dump({
            "total": len(all_unknown_markets),
            "patterns": {
                "dates": date_patterns_count,
                "prices": price_patterns_count,
                "questions": question_patterns_count,
                "numbers": number_patterns_count
            },
            "data_availability": {
                "has_slug": has_slug_count,
                "has_question": has_question_count,
                "has_description": has_description_count,
                "empty": empty_count
            },
            "text_lengths": {
                "avg": avg_length,
                "short": len(short_texts),
                "medium": len(medium_texts),
                "long": len(long_texts)
            },
            "top_keywords": dict(keywords.most_common(50)),
            "samples": all_unknown_markets[:100]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 100 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        }, f, indent=2)
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ unknown_markets_analysis.json")
    
    print("\n" + "=" * 80)
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 80)
    
    recommendations = []
    
    if empty_count > len(all_unknown_markets) * 0.3:
        recommendations.append("1. ‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ù–û: –ú–Ω–æ–≥–æ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö - —É–ª—É—á—à–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –≤—Å–µ API")
    
    if date_patterns_count > 0:
        recommendations.append("2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ –¥–∞—Ç–∞–º")
    
    if price_patterns_count > 0:
        recommendations.append("3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ —Ü–µ–Ω–∞–º")
    
    if len(short_texts) > len(all_unknown_markets) * 0.2:
        recommendations.append("4. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ML –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)")
    
    top_keywords_list = [w for w, c in keywords.most_common(30) if c >= 2]
    if top_keywords_list:
        recommendations.append(f"5. üìù –î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é: {', '.join(top_keywords_list[:15])}")
    
    for rec in recommendations:
        print(f"   {rec}")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    analyze_unknown_markets()

