#!/usr/bin/env python3
"""
Analyze remaining Unknown markets to identify patterns and improve classification
"""

import os
import sys
import requests
from collections import Counter
from typing import List, Dict, Any
from dotenv import load_dotenv
from db import PolymarketDB

load_dotenv()

def get_unknown_markets_sample(db: PolymarketDB, limit: int = 1000) -> List[Dict[str, Any]]:
    """Get sample of wallets with Unknown categories"""
    with db.get_connection() as conn:
        cursor = conn.cursor()
        
        # Get wallets with Unknown categories
        cursor.execute('''
            SELECT DISTINCT wallet_address, SUM(markets) as unknown_markets
            FROM wallet_category_stats
            WHERE category = "other/Unknown"
            GROUP BY wallet_address
            ORDER BY unknown_markets DESC
            LIMIT ?
        ''', (limit,))
        
        return cursor.fetchall()

def fetch_closed_positions(address: str, limit: int = 50) -> List[Dict[str, Any]]:
    """Fetch closed positions for a wallet"""
    try:
        url = "https://data-api.polymarket.com/closed-positions"
        params = {"user": address, "limit": limit}
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            return response.json() if isinstance(response.json(), list) else []
        return []
    except Exception as e:
        print(f"Error fetching positions for {address[:20]}...: {e}")
        return []

def get_market_data_from_clob(condition_id: str) -> Dict[str, Any]:
    """Get market data from CLOB API"""
    try:
        url = f"https://clob.polymarket.com/markets/{condition_id}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            return response.json()
        return {}
    except Exception as e:
        return {}

def analyze_unknown_markets():
    """Analyze Unknown markets to find patterns"""
    db_path = os.getenv('DB_PATH', 'polymarket_notifier.db')
    if not os.path.isabs(db_path):
        db_path = os.path.abspath(db_path)
    
    db = PolymarketDB(db_path)
    
    print("=" * 100)
    print("–ê–ù–ê–õ–ò–ó UNKNOWN –†–´–ù–ö–û–í (–§–ê–ó–ê 3)")
    print("=" * 100)
    print()
    
    # Get sample wallets
    print("üìã –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ—à–µ–ª—å–∫–æ–≤ —Å Unknown –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏...")
    wallets = get_unknown_markets_sample(db, limit=100)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(wallets)} –∫–æ—à–µ–ª—å–∫–æ–≤ —Å Unknown –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏")
    print()
    
    all_titles = []
    all_slugs = []
    all_keywords = []
    markets_with_data = 0
    markets_without_data = 0
    
    print("üîç –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–æ–≤...")
    print()
    
    for i, (wallet_addr, unknown_count) in enumerate(wallets[:50], 1):  # Analyze first 50 wallets
        print(f"[{i}/{min(50, len(wallets))}] –ö–æ—à–µ–ª—ë–∫: {wallet_addr[:20]}... ({unknown_count} Unknown —Ä—ã–Ω–∫–æ–≤)")
        
        positions = fetch_closed_positions(wallet_addr, limit=50)
        
        for pos in positions[:20]:  # Analyze first 20 positions per wallet
            condition_id = pos.get("conditionId") or pos.get("condition_id")
            if not condition_id:
                continue
            
            # Get data from position
            title = pos.get("title")
            slug = pos.get("slug") or pos.get("eventSlug")
            
            # If no data, try CLOB API
            if not title and not slug:
                clob_data = get_market_data_from_clob(condition_id)
                title = clob_data.get("question") or clob_data.get("title")
                slug = clob_data.get("slug") or clob_data.get("market_slug")
            
            if title or slug:
                markets_with_data += 1
                if title:
                    all_titles.append(title.lower())
                    # Extract words
                    words = title.lower().replace('-', ' ').replace('_', ' ').replace('?', '').replace('!', '').split()
                    all_keywords.extend([w for w in words if len(w) > 2])
                
                if slug:
                    all_slugs.append(slug.lower())
                    words = slug.lower().replace('-', ' ').replace('_', ' ').split()
                    all_keywords.extend([w for w in words if len(w) > 2])
            else:
                markets_without_data += 1
        
        if i % 10 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i} –∫–æ—à–µ–ª—å–∫–æ–≤...")
    
    print()
    print("=" * 100)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 100)
    print()
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚Ä¢ –†—ã–Ω–∫–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {markets_with_data}")
    print(f"   ‚Ä¢ –†—ã–Ω–∫–æ–≤ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö: {markets_without_data}")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {markets_with_data + markets_without_data}")
    print()
    
    if markets_without_data > 0:
        pct_no_data = markets_without_data / (markets_with_data + markets_without_data) * 100
        print(f"‚ö†Ô∏è  {pct_no_data:.1f}% —Ä—ã–Ω–∫–æ–≤ –Ω–µ –∏–º–µ—é—Ç –¥–∞–Ω–Ω—ã—Ö (title/slug)")
        print()
    
    if all_titles:
        print(f"üìù –ü—Ä–∏–º–µ—Ä—ã Unknown —Ä—ã–Ω–∫–æ–≤ (–ø–µ—Ä–≤—ã–µ 20):")
        for i, title in enumerate(all_titles[:20], 1):
            print(f"   {i}. {title[:80]}")
        print()
    
    if all_keywords:
        print(f"üîë –¢–æ–ø-50 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ Unknown —Ä—ã–Ω–∫–æ–≤:")
        keyword_counts = Counter(all_keywords)
        
        # Filter out common stop words
        stop_words = {'will', 'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'its', 'may', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 'did', 'its', 'let', 'put', 'say', 'she', 'too', 'use'}
        
        filtered_keywords = Counter({k: v for k, v in keyword_counts.items() if k not in stop_words and len(k) > 2})
        
        for keyword, count in filtered_keywords.most_common(50):
            print(f"   ‚Ä¢ {keyword:<20} ({count} —Ä–∞–∑)")
        print()
    
    # Analyze patterns
    print("üîç –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:")
    print()
    
    # Check for common patterns
    patterns = {
        'dates': sum(1 for t in all_titles if any(month in t for month in ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december'])),
        'numbers': sum(1 for t in all_titles if any(char.isdigit() for char in t)),
        'questions': sum(1 for t in all_titles if '?' in t),
        'crypto_mentions': sum(1 for t in all_titles if any(crypto in t for crypto in ['bitcoin', 'ethereum', 'crypto', 'btc', 'eth'])),
        'sports_mentions': sum(1 for t in all_titles if any(sport in t for sport in ['nfl', 'nba', 'nhl', 'mlb', 'soccer', 'football', 'basketball'])),
        'politics_mentions': sum(1 for t in all_titles if any(pol in t for pol in ['election', 'president', 'trump', 'biden', 'vote'])),
    }
    
    for pattern, count in patterns.items():
        if count > 0:
            pct = count / len(all_titles) * 100 if all_titles else 0
            print(f"   ‚Ä¢ {pattern}: {count} ({pct:.1f}%)")
    
    print()
    print("=" * 100)
    print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print("=" * 100)
    print()
    
    if markets_without_data > markets_with_data:
        print("1. ‚ö†Ô∏è  –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ API")
        print("   ‚Üí –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–ª—É—á—à–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (GraphQL API, –ø–∞—Ä—Å–∏–Ω–≥ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü)")
        print()
    
    if all_keywords:
        print("2. üìù –†–∞—Å—à–∏—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ø-50 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤")
        print()
    
    if patterns.get('dates', 0) > len(all_titles) * 0.3:
        print("3. üìÖ –ú–Ω–æ–≥–æ —Ä—ã–Ω–∫–æ–≤ —Å –¥–∞—Ç–∞–º–∏ - –≤–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è 'events/Dates'")
        print()
    
    print("=" * 100)

if __name__ == "__main__":
    analyze_unknown_markets()

