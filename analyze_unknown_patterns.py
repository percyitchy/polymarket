#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è Unknown —Ä—ã–Ω–∫–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
"""

import os
import sys
import logging
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from dotenv import load_dotenv
from db import PolymarketDB

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def analyze_unknown_markets(db_path='polymarket_notifier.db'):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Unknown —Ä—ã–Ω–∫–∏ –∏–∑ wallet_category_stats"""
    db = PolymarketDB(db_path)
    
    with db.get_connection() as conn:
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ Unknown —Ä—ã–Ω–∫–∏ —Å –∏—Ö –¥–∞–Ω–Ω—ã–º–∏
        cursor.execute("""
            SELECT DISTINCT wallet_address, category
            FROM wallet_category_stats
            WHERE category = 'other/Unknown'
            LIMIT 1000
        """)
        
        unknown_wallets = cursor.fetchall()
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(unknown_wallets)} –∫–æ—à–µ–ª—å–∫–æ–≤ —Å Unknown –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã Unknown —Ä—ã–Ω–∫–æ–≤ –∏–∑ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π
        # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å condition_id –∏–∑ –∑–∞–∫—Ä—ã—Ç—ã—Ö –ø–æ–∑–∏—Ü–∏–π —ç—Ç–∏—Ö –∫–æ—à–µ–ª—å–∫–æ–≤
        condition_ids = set()
        wallet_addresses = [w[0] for w in unknown_wallets[:100]]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ—à–µ–ª—å–∫–∏: {len(wallet_addresses)}")
        
        # –ü–æ–ª—É—á–∞–µ–º condition_id –∏–∑ rolling_buys (–µ—Å–ª–∏ –µ—Å—Ç—å)
        for wallet in wallet_addresses[:50]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            try:
                cursor.execute("""
                    SELECT data FROM rolling_buys
                    WHERE k LIKE ?
                    LIMIT 10
                """, (f"%{wallet}%",))
                
                results = cursor.fetchall()
                for row in results:
                    try:
                        import json
                        data = json.loads(row[0])
                        events = data.get("events", [])
                        for event in events:
                            cond_id = event.get("conditionId") or event.get("condition_id")
                            if cond_id:
                                condition_ids.add(cond_id)
                    except:
                        pass
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {wallet[:12]}...: {e}")
        
        logger.info(f"–°–æ–±—Ä–∞–Ω–æ {len(condition_ids)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö condition_id –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ä—ã–Ω–∫–∞—Ö —á–µ—Ä–µ–∑ API
        from gamma_client import get_event_by_condition_id
        
        market_data = []
        analyzed = 0
        
        for condition_id in list(condition_ids)[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            try:
                event = get_event_by_condition_id(condition_id)
                if event:
                    markets = event.get("markets", [])
                    for market in markets:
                        market_condition_id = market.get("conditionId") or market.get("condition_id")
                        if market_condition_id and market_condition_id.lower() == condition_id.lower():
                            slug = market.get("slug") or market.get("marketSlug") or ""
                            question = market.get("question") or market.get("title") or ""
                            description = market.get("description") or ""
                            
                            market_data.append({
                                "condition_id": condition_id,
                                "slug": slug,
                                "question": question,
                                "description": description,
                                "full_text": f"{slug} {question} {description}".lower()
                            })
                            break
                    
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ markets, –∏—Å–ø–æ–ª—å–∑—É–µ–º event –¥–∞–Ω–Ω—ã–µ
                    if not any(m.get("condition_id") == condition_id for m in market_data):
                        slug = event.get("slug") or event.get("eventSlug") or ""
                        question = event.get("question") or event.get("title") or ""
                        description = event.get("description") or ""
                        
                        market_data.append({
                            "condition_id": condition_id,
                            "slug": slug,
                            "question": question,
                            "description": description,
                            "full_text": f"{slug} {question} {description}".lower()
                        })
                
                analyzed += 1
                if analyzed % 10 == 0:
                    logger.info(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {analyzed}/{len(condition_ids)} —Ä—ã–Ω–∫–æ–≤...")
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {condition_id[:20]}...: {e}")
        
        logger.info(f"–°–æ–±—Ä–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ {len(market_data)} —Ä—ã–Ω–∫–∞—Ö")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        print("\n" + "=" * 80)
        print("üìä –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í UNKNOWN –†–´–ù–ö–û–í")
        print("=" * 80)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keywords = Counter()
        common_words = Counter()
        
        for market in market_data:
            text = market["full_text"]
            words = text.split()
            
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            stop_words = {
                "will", "the", "be", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
                "of", "with", "by", "from", "as", "is", "are", "was", "were", "been", "being",
                "have", "has", "had", "do", "does", "did", "this", "that", "these", "those",
                "what", "which", "who", "when", "where", "why", "how", "if", "than", "then"
            }
            
            for word in words:
                word_clean = word.strip(".,!?;:()[]{}'\"").lower()
                if len(word_clean) > 3 and word_clean not in stop_words:
                    keywords[word_clean] += 1
                    common_words[word_clean] += 1
        
        print("\nüî§ –¢–æ–ø-30 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ Unknown —Ä—ã–Ω–∫–∞—Ö:")
        for word, count in keywords.most_common(30):
            print(f"   {word:<20} {count:>4}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns = {
            "dates": [],
            "numbers": [],
            "questions": [],
            "short_text": [],
            "empty_data": []
        }
        
        for market in market_data:
            text = market["full_text"]
            question = market["question"]
            slug = market["slug"]
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å –¥–∞—Ç–∞–º–∏
            import re
            if re.search(r'\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}/\d{4}|january|february|march|april|may|june|july|august|september|october|november|december', text, re.IGNORECASE):
                patterns["dates"].append(market)
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å —á–∏—Å–ª–∞–º–∏ (—Ü–µ–Ω—ã, –ø—Ä–æ—Ü–µ–Ω—Ç—ã)
            if re.search(r'\$[\d,]+|\d+%|\d+\.\d+%', text):
                patterns["numbers"].append(market)
            
            # –í–æ–ø—Ä–æ—Å—ã
            if question and '?' in question:
                patterns["questions"].append(market)
            
            # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
            if len(text) < 20:
                patterns["short_text"].append(market)
            
            # –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
            if not text or text.strip() == "":
                patterns["empty_data"].append(market)
        
        print("\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º:")
        print(f"   –†—ã–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏: {len(patterns['dates'])}")
        print(f"   –†—ã–Ω–∫–∏ —Å —á–∏—Å–ª–∞–º–∏/—Ü–µ–Ω–∞–º–∏: {len(patterns['numbers'])}")
        print(f"   –†—ã–Ω–∫–∏-–≤–æ–ø—Ä–æ—Å—ã: {len(patterns['questions'])}")
        print(f"   –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (<20 —Å–∏–º–≤–æ–ª–æ–≤): {len(patterns['short_text'])}")
        print(f"   –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(patterns['empty_data'])}")
        
        # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        print("\nüìù –ü—Ä–∏–º–µ—Ä—ã Unknown —Ä—ã–Ω–∫–æ–≤:")
        print("\n1. –†—ã–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏:")
        for market in patterns["dates"][:5]:
            print(f"   ‚Ä¢ {market['question'][:80] or market['slug'][:80]}")
        
        print("\n2. –†—ã–Ω–∫–∏ —Å —á–∏—Å–ª–∞–º–∏/—Ü–µ–Ω–∞–º–∏:")
        for market in patterns["numbers"][:5]:
            print(f"   ‚Ä¢ {market['question'][:80] or market['slug'][:80]}")
        
        print("\n3. –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç:")
        for market in patterns["short_text"][:5]:
            print(f"   ‚Ä¢ {market['question'][:80] or market['slug'][:80]}")
        
        print("\n4. –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        for market in patterns["empty_data"][:5]:
            print(f"   ‚Ä¢ condition_id: {market['condition_id'][:40]}...")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\n" + "=" * 80)
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
        print("=" * 80)
        
        recommendations = []
        
        if len(patterns["empty_data"]) > len(market_data) * 0.3:
            recommendations.append("‚ö†Ô∏è  –ú–Ω–æ–≥–æ —Ä—ã–Ω–∫–æ–≤ —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ - —É–ª—É—á—à–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ GraphQL/web scraping")
        
        if len(patterns["short_text"]) > len(market_data) * 0.2:
            recommendations.append("‚ö†Ô∏è  –ú–Ω–æ–≥–æ —Ä—ã–Ω–∫–æ–≤ —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å description –∏–∑ API")
        
        if len(patterns["dates"]) > 0:
            recommendations.append("‚úÖ –î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º (—Å–æ–±—ã—Ç–∏—è, –¥–µ–¥–ª–∞–π–Ω—ã)")
        
        if len(patterns["numbers"]) > 0:
            recommendations.append("‚úÖ –î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Ü–µ–Ω–∞–º/–ø—Ä–æ—Ü–µ–Ω—Ç–∞–º (–º–∞–∫—Ä–æ, –∫—Ä–∏–ø—Ç–æ)")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        top_keywords = [w for w, c in keywords.most_common(50) if c >= 2]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –ø–æ–∫—Ä—ã—Ç—ã —Ç–µ–∫—É—â–∏–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        from market_utils import (
            NFL_TEAMS, NBA_TEAMS, NHL_TEAMS, MLB_TEAMS,
            CRYPTO_KEYWORDS, POLITICS_KEYWORDS, MACRO_KEYWORDS,
            STOCKS_KEYWORDS, ENTERTAINMENT_KEYWORDS, TECH_KEYWORDS
        )
        
        all_known_keywords = set()
        for kw_list in [NFL_TEAMS, NBA_TEAMS, NHL_TEAMS, MLB_TEAMS,
                        CRYPTO_KEYWORDS, POLITICS_KEYWORDS, MACRO_KEYWORDS,
                        STOCKS_KEYWORDS, ENTERTAINMENT_KEYWORDS, TECH_KEYWORDS]:
            all_known_keywords.update([k.lower() for k in kw_list])
        
        unknown_keywords = [kw for kw in top_keywords if kw not in all_known_keywords]
        
        if unknown_keywords:
            recommendations.append(f"üìù –ù–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {', '.join(unknown_keywords[:20])}")
        
        for rec in recommendations:
            print(f"   {rec}")
        
        print("\n" + "=" * 80)
        
        return {
            "total_analyzed": len(market_data),
            "patterns": patterns,
            "top_keywords": dict(keywords.most_common(30)),
            "unknown_keywords": unknown_keywords[:20],
            "recommendations": recommendations
        }

if __name__ == "__main__":
    db_path = os.getenv('DB_PATH', 'polymarket_notifier.db')
    if not os.path.isabs(db_path):
        db_path = os.path.abspath(db_path)
    
    results = analyze_unknown_markets(db_path)
    
    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {results['total_analyzed']} —Ä—ã–Ω–∫–æ–≤.")
