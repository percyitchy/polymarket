#!/usr/bin/env python3
"""
–ü—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑ Unknown —Ä—ã–Ω–∫–æ–≤ —á–µ—Ä–µ–∑ API
"""

import os
import sys
import logging
from collections import Counter
from dotenv import load_dotenv
from db import PolymarketDB
from market_utils import classify_market

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def analyze_unknown_from_api():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Unknown —Ä—ã–Ω–∫–∏ —á–µ—Ä–µ–∑ API"""
    import requests
    
    print("=" * 80)
    print("üìä –ê–ù–ê–õ–ò–ó UNKNOWN –†–´–ù–ö–û–í –ß–ï–†–ï–ó API")
    print("=" * 80)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ Gamma API
    print("\nüì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π —á–µ—Ä–µ–∑ Gamma API...")
    try:
        url = "https://gamma-api.polymarket.com/events"
        params = {"limit": 200, "featured": "true"}
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code != 200:
            logger.error(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
            return
        
        data = response.json()
        events = []
        if isinstance(data, list):
            events = data
        elif isinstance(data, dict):
            events = data.get("data") or data.get("events") or []
        
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(events)} —Å–æ–±—ã—Ç–∏–π")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Ä—ã–Ω–∫–∏ –∏–∑ —Å–æ–±—ã—Ç–∏–π
        markets = []
        for event in events:
            event_markets = event.get("markets", [])
            for market in event_markets:
                market["event"] = event  # –°–æ—Ö—Ä–∞–Ω—è–µ–º event –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                markets.append(market)
        
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(markets)} —Ä—ã–Ω–∫–æ–≤ –∏–∑ —Å–æ–±—ã—Ç–∏–π")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä—ã–Ω–∫–æ–≤: {e}")
        return
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ä—ã–Ω–æ–∫
    unknown_markets = []
    classified_markets = []
    
    print("\nüîç –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä—ã–Ω–∫–æ–≤...")
    for i, market in enumerate(markets):
        if i % 50 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(markets)}...")
        
        condition_id = market.get("conditionId") or market.get("condition_id")
        slug = market.get("slug") or market.get("marketSlug") or ""
        question = market.get("question") or market.get("title") or ""
        description = market.get("description") or ""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º event –∏–∑ market (—É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤—ã—à–µ)
        event = market.get("event", {})
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
        category = classify_market(event, slug, question or description)
        
        market_info = {
            "condition_id": condition_id,
            "slug": slug,
            "question": question,
            "description": description,
            "category": category,
            "full_text": f"{slug} {question} {description}".lower()
        }
        
        if category == "other/Unknown":
            unknown_markets.append(market_info)
        else:
            classified_markets.append(market_info)
    
    print(f"\n‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {len(classified_markets)}")
    print(f"‚ùì Unknown: {len(unknown_markets)}")
    print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç Unknown: {len(unknown_markets) / len(markets) * 100:.2f}%")
    
    if not unknown_markets:
        print("\n‚úÖ –í—Å–µ —Ä—ã–Ω–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã!")
        return
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ Unknown —Ä—ã–Ω–∫–æ–≤
    print("\n" + "=" * 80)
    print("üîç –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í UNKNOWN –†–´–ù–ö–û–í")
    print("=" * 80)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = Counter()
    stop_words = {
        "will", "the", "be", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
        "of", "with", "by", "from", "as", "is", "are", "was", "were", "been", "being",
        "have", "has", "had", "do", "does", "did", "this", "that", "these", "those",
        "what", "which", "who", "when", "where", "why", "how", "if", "than", "then",
        "more", "most", "some", "any", "all", "each", "every", "other", "another"
    }
    
    for market in unknown_markets:
        text = market["full_text"]
        words = text.split()
        
        for word in words:
            word_clean = word.strip(".,!?;:()[]{}'\"-").lower()
            if len(word_clean) > 3 and word_clean not in stop_words:
                keywords[word_clean] += 1
    
    print("\nüî§ –¢–æ–ø-30 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ Unknown —Ä—ã–Ω–∫–∞—Ö:")
    for word, count in keywords.most_common(30):
        print(f"   {word:<25} {count:>4}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
    import re
    
    patterns = {
        "dates": [],
        "numbers": [],
        "questions": [],
        "short_text": [],
        "empty_data": [],
        "specific_keywords": []
    }
    
    for market in unknown_markets:
        text = market["full_text"]
        question = market["question"]
        slug = market["slug"]
        
        # –î–∞—Ç—ã
        if re.search(r'\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}/\d{4}|january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec', text, re.IGNORECASE):
            patterns["dates"].append(market)
        
        # –ß–∏—Å–ª–∞/—Ü–µ–Ω—ã
        if re.search(r'\$[\d,]+|\d+%|\d+\.\d+%|\d+[km]?', text):
            patterns["numbers"].append(market)
        
        # –í–æ–ø—Ä–æ—Å—ã
        if question and '?' in question:
            patterns["questions"].append(market)
        
        # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
        if len(text) < 20:
            patterns["short_text"].append(market)
        
        # –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
        if not text or text.strip() == "":
            patterns["empty_data"].append(market)
    
    print("\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º:")
    print(f"   –†—ã–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏: {len(patterns['dates'])} ({len(patterns['dates'])/len(unknown_markets)*100:.1f}%)")
    print(f"   –†—ã–Ω–∫–∏ —Å —á–∏—Å–ª–∞–º–∏/—Ü–µ–Ω–∞–º–∏: {len(patterns['numbers'])} ({len(patterns['numbers'])/len(unknown_markets)*100:.1f}%)")
    print(f"   –†—ã–Ω–∫–∏-–≤–æ–ø—Ä–æ—Å—ã: {len(patterns['questions'])} ({len(patterns['questions'])/len(unknown_markets)*100:.1f}%)")
    print(f"   –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (<20 —Å–∏–º–≤–æ–ª–æ–≤): {len(patterns['short_text'])} ({len(patterns['short_text'])/len(unknown_markets)*100:.1f}%)")
    print(f"   –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(patterns['empty_data'])} ({len(patterns['empty_data'])/len(unknown_markets)*100:.1f}%)")
    
    # –ü—Ä–∏–º–µ—Ä—ã
    print("\nüìù –ü—Ä–∏–º–µ—Ä—ã Unknown —Ä—ã–Ω–∫–æ–≤:")
    
    if patterns["dates"]:
        print("\n1. –†—ã–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏:")
        for market in patterns["dates"][:5]:
            print(f"   ‚Ä¢ {market['question'][:100] or market['slug'][:100]}")
    
    if patterns["numbers"]:
        print("\n2. –†—ã–Ω–∫–∏ —Å —á–∏—Å–ª–∞–º–∏/—Ü–µ–Ω–∞–º–∏:")
        for market in patterns["numbers"][:5]:
            print(f"   ‚Ä¢ {market['question'][:100] or market['slug'][:100]}")
    
    if patterns["short_text"]:
        print("\n3. –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç:")
        for market in patterns["short_text"][:5]:
            print(f"   ‚Ä¢ {market['question'][:100] or market['slug'][:100]}")
    
    if patterns["empty_data"]:
        print("\n4. –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        for market in patterns["empty_data"][:5]:
            print(f"   ‚Ä¢ condition_id: {market['condition_id'][:40] if market['condition_id'] else 'N/A'}...")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "=" * 80)
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 80)
    
    recommendations = []
    
    if len(patterns["empty_data"]) > len(unknown_markets) * 0.3:
        recommendations.append("‚ö†Ô∏è  –ú–Ω–æ–≥–æ —Ä—ã–Ω–∫–æ–≤ —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ - —É–ª—É—á—à–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ GraphQL/web scraping")
    
    if len(patterns["short_text"]) > len(unknown_markets) * 0.2:
        recommendations.append("‚ö†Ô∏è  –ú–Ω–æ–≥–æ —Ä—ã–Ω–∫–æ–≤ —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å description –∏–∑ API")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    top_keywords = [w for w, c in keywords.most_common(50) if c >= 2]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –ø–æ–∫—Ä—ã—Ç—ã
    from market_utils import (
        NFL_TEAMS, NBA_TEAMS, NHL_TEAMS, MLB_TEAMS,
        CRYPTO_KEYWORDS, POLITICS_KEYWORDS, MACRO_KEYWORDS,
        STOCKS_KEYWORDS, ENTERTAINMENT_KEYWORDS, TECH_KEYWORDS
    )
    
    all_known_keywords = set()
    for kw_list in [NFL_TEAMS, NBA_TEAMS, NHL_TEAMS, MLB_TEAMS,
                    CRYPTO_KEYWORDS, POLITICS_KEYWORDS, MACRO_KEYWORDS,
                    STOCKS_KEYWORDS, ENTERTAINMENT_KEYWORDS, TECH_KEYWORDS]:
        all_known_keywords.update([k.lower() for k in kw_list])
    
    unknown_keywords = [kw for kw in top_keywords if kw not in all_known_keywords]
    
    if unknown_keywords:
        recommendations.append(f"üìù –ù–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {', '.join(unknown_keywords[:20])}")
    
    for rec in recommendations:
        print(f"   {rec}")
    
    print("\n" + "=" * 80)
    
    return {
        "total": len(markets),
        "unknown": len(unknown_markets),
        "unknown_pct": len(unknown_markets) / len(markets) * 100 if markets else 0,
        "patterns": patterns,
        "top_keywords": dict(keywords.most_common(30)),
        "unknown_keywords": unknown_keywords[:20]
    }

if __name__ == "__main__":
    results = analyze_unknown_from_api()
    if results:
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω.")
        print(f"   –í—Å–µ–≥–æ —Ä—ã–Ω–∫–æ–≤: {results['total']}")
        print(f"   Unknown: {results['unknown']} ({results['unknown_pct']:.2f}%)")

